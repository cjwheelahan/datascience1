{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/AC 209A/STAT 121A Data Science: Midterm 2\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**Instructors: W. Pan, P. Protopapas, K. Rader**<br>\n",
    "**Due Date: ** Tuesday, November 22nd, 2016 at 12:00pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.ensemble import AdaBoostClassifier as AdaBoost\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Diagnosing the Semian Flu 2016\n",
    "\n",
    "You are given the early data for an outbreak of a dangerous virus originating from a group of primates being keeped in a Massechussetts biomedical research lab, this virus is dubbed the \"Semian Flu\".\n",
    "\n",
    "You have the medical records of $n$ number of patients in `'flu_train.csv`. There are two general types of patients in the data, flu patients and healthy (this is recorded in the column labeled `flu`, a 0 indicates the absences of the virus and a 1 indicates presence). Furthermore, scientists have found that there are two strains of the virus, each requiring a different type of treatment (this is recorded in the column labeled `flutype`, a 1 indicates the absences of the virus, a 2 indicates presence of strain 1 and a 3 indicates the presence of strain 2).\n",
    "\n",
    "**Your task:** build a model to predict if a given patient has the flu. Your goal is to catch as many flu patients as possible without misdiagnosing too many healthy patients.\n",
    "\n",
    "**The deliverable:** a function called `flu_predict` which satisfies:\n",
    "\n",
    "- input: `x_test`, a set of medical predictors for a group of patients\n",
    "- output: `y_pred`, a set of labels, one for each patient; 0 for healthy and 1 for infected with the flu virus\n",
    "\n",
    "The MA state government will use your model to diagnose sets of future patients (held by us). You can expect that there will be an increase in the number of flu patients in any groups of patients in the future.\n",
    "\n",
    "We provide you with some benchmarks for comparison.\n",
    "\n",
    "**Baseline Model:** \n",
    "- ~50% expected accuracy on healthy patients in observed data\n",
    "- ~50% expected accuracy on flu patients in observed data\n",
    "- ~50% expected accuracy on healthy patients in future data \n",
    "- ~50% expected accuracy on flu patients in future data\n",
    "- time to build: 5 min\n",
    "\n",
    "**Reasonable Model:** \n",
    "- ~69% expected accuracy on healthy patients in observed data\n",
    "- ~55% expected accuracy on flu patients, in observed data\n",
    "- ~69% expected accuracy on healthy patients in future data\n",
    "- ~60% expected accuracy on flu patients, in future data\n",
    "- time to build: 20 min\n",
    "\n",
    "**Grading:**\n",
    "Your grade will be based on:\n",
    "1. your model's ability to out-perform our benchmarks\n",
    "2. your ability to carefully and thoroughly follow the data science pipeline (see lecture slides for definition)\n",
    "3. the extend to which all choices are reasonable and defensible by methods you have learned in this class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Import and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the dataset, there are 5246 entries, with 76 datapoints each.\n",
      "Potential covariates are:\n",
      "-------------------------\n",
      "ID\n",
      "Gender\n",
      "Age\n",
      "AgeDecade\n",
      "AgeMonths\n",
      "Race1\n",
      "Race3\n",
      "Education\n",
      "MaritalStatus\n",
      "HHIncome\n",
      "HHIncomeMid\n",
      "Poverty\n",
      "HomeRooms\n",
      "HomeOwn\n",
      "Work\n",
      "Weight\n",
      "Length\n",
      "HeadCirc\n",
      "Height\n",
      "BMI\n",
      "BMICatUnder20yrs\n",
      "BMI_WHO\n",
      "Pulse\n",
      "BPSysAve\n",
      "BPDiaAve\n",
      "BPSys1\n",
      "BPDia1\n",
      "BPSys2\n",
      "BPDia2\n",
      "BPSys3\n",
      "BPDia3\n",
      "Testosterone\n",
      "DirectChol\n",
      "TotChol\n",
      "UrineVol1\n",
      "UrineFlow1\n",
      "UrineVol2\n",
      "UrineFlow2\n",
      "Diabetes\n",
      "DiabetesAge\n",
      "HealthGen\n",
      "DaysMentHlthBad\n",
      "LittleInterest\n",
      "Depressed\n",
      "nPregnancies\n",
      "nBabies\n",
      "Age1stBaby\n",
      "SleepHrsNight\n",
      "SleepTrouble\n",
      "PhysActive\n",
      "PhysActiveDays\n",
      "TVHrsDay\n",
      "CompHrsDay\n",
      "TVHrsDayChild\n",
      "CompHrsDayChild\n",
      "Alcohol12PlusYr\n",
      "AlcoholDay\n",
      "AlcoholYear\n",
      "SmokeNow\n",
      "Smoke100\n",
      "Smoke100n\n",
      "SmokeAge\n",
      "Marijuana\n",
      "AgeFirstMarij\n",
      "RegularMarij\n",
      "AgeRegMarij\n",
      "HardDrugs\n",
      "SexEver\n",
      "SexAge\n",
      "SexNumPartnLife\n",
      "SexNumPartYear\n",
      "SameSex\n",
      "SexOrientation\n",
      "PregnantNow\n",
      "flu\n",
      "flutype\n",
      "-------------------------\n",
      "The flu has an overall prevalence of 0.059\n"
     ]
    }
   ],
   "source": [
    "flu_data = pd.read_csv('flu_train.csv', delimiter=',', header=0)\n",
    "\n",
    "print \"In the dataset, there are\", flu_data.shape[0], \"entries, with\", flu_data.shape[1], \"datapoints each.\"\n",
    "print \"Potential covariates are:\"\n",
    "print \"-------------------------\"\n",
    "for each in range(len(flu_data.columns)):\n",
    "    print flu_data.columns[each]\n",
    "print \"-------------------------\"\n",
    "print \"The flu has an overall prevalence of\", round((np.sum(flu_data['flu'])/float(len(flu_data))), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Clean and Split data\n",
    "We need to create our own training and test set from the data we have. Since there are so many covariates, we will also probably have to do some tuning, so a validation set would be good to have as well. I'm assuming the data is not grouped in any particular way, but will check the overall prevalences of the flu to be sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping Columns\n",
    "There are a number of columns that are duplicative or do not hold any useful information. We'll drop those. For a complete list of dropped columns, please see Appendix A.\n",
    "\n",
    "#### Missing Data\n",
    "We have a lot of missing data here. If this was a full research study, we could go through the data and really make a decision as to whether the columns were needed (e.g., Age, Age Decade and Age Months are not all necessary), then either impute or ignore missing data after that point. Since this is an exam with limited time and I don't have the expertise to do that, I'm going to fill missing values with a 0. We'll keep this in mind as we move forward (as it could definitely introduce some bias) but it shouldn't be a major problem.\n",
    "\n",
    "#### Dummies\n",
    "There are many categorical variables in this dataset. We'll hot-encode new columns for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split data\n",
    "x = flu_data.iloc[:, :-2]\n",
    "y = flu_data.iloc[:, -2]\n",
    "\n",
    "#drop duplicative/unnecessary columns\n",
    "cols = [2,3,9,11,16,17,20,21,25,26,27,28,29,30,36,37,42,43,48,49,57,59]\n",
    "x.drop(x.columns[cols],axis=1,inplace=True)\n",
    "\n",
    "#fill missing data\n",
    "x.fillna(0, inplace=True)\n",
    "\n",
    "# Create a new data frame to store one-hot encoding of attributes\n",
    "flu_data_expanded = pd.DataFrame({}) \n",
    "\n",
    "# Iterate over all attributes\n",
    "for column in x.columns:\n",
    "    # Check if attribute is categorical: has less than 8 unique values,\n",
    "    # or is string values (column has type 'object')\n",
    "    if len(x[column].unique()) < 8 or x[column].dtype == np.dtype('object'):\n",
    "        # use one-hot encoding for this column\n",
    "        encoding = pd.get_dummies(x[column])\n",
    "        # append expanded attribute to data frame\n",
    "        flu_data_expanded = pd.concat([flu_data_expanded, encoding], axis=1)\n",
    "    else:\n",
    "        flu_data_expanded = pd.concat([flu_data_expanded, x[[column]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence in train: 0.059\n",
      "Prevalence in validation: 0.067\n",
      "Prevalence in test: 0.058\n"
     ]
    }
   ],
   "source": [
    "#split data\n",
    "x_train = flu_data_expanded.iloc[:525, :]\n",
    "y_train = y.iloc[:525]\n",
    "x_val = flu_data_expanded.iloc[525:1050, :]\n",
    "y_val = y.iloc[525:1050]\n",
    "x_test = flu_data_expanded.iloc[1050:, :]\n",
    "y_test = y.iloc[1050:]\n",
    "\n",
    "print \"Prevalence in train:\", round(np.sum(y_train)/float(len(y_train)), 3)\n",
    "print \"Prevalence in validation:\", round(np.sum(y_val)/float(len(y_val)), 3)\n",
    "print \"Prevalence in test:\", round(np.sum(y_test)/float(len(y_test)), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Try something and tune our parameters\n",
    "I'm really not sure which technique would best classify our data. We tried some things that didn't work very well (found in Appendix E)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEZCAYAAAC5AHPcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd4VNXWwOHfCr0TQAHpiAqIiqiIIhpRFKXKVaR4sWC5\nXsResCDYroBc+9VPRQFFigUFRBAEAzZApYiAgAqIICA99JCs74+9B4Y4SSbJTGYS1vs882Tm1HXO\nTM46Z+999hFVxRhjjMmphFgHYIwxpmCyBGKMMSZXLIEYY4zJFUsgxhhjcsUSiDHGmFyxBGKMMSZX\nLIGYQ0TkRBFZICI7ROS2fFxvLRHZKSKSX+v06z1WRGb77X0mP9cdSSJyrYh8mYf5HxSR1yMZk1/u\nqyLycKSXa+LHUZNAROQ8EflaRLaLyGYR+VJEzoh1XHHmfmCmqlZQ1ZejtRIRWSUirQOfVXWtqpbX\n/L8p6WZgk9/e+/KyIBG5QETSfCLcISLLROS6yIQZllzvO1V9WlVvzsvKQyUxVb1VVZ/Ky3ILGxH5\nQkRuiMIyzxeRASLyaNDwciLyvIis8b/LlSLyrIhU8uNXiUhtERkuIr1ys+6jIoGISDlgEvACkAjU\nAB4D9kd4PQV9f9YBlsQ6iHxUB1gaweWt84mwAnA38IaInBDB5UeciBSJ1KLIQxKLlQhuf74I9xgj\nIsWAmUAj4BJVLQ+cA2wGmkcsIFUt9C/gDGBrNtPchDuY7AR+Apr64Q2BL4BtwGKgQ9A8w4FXgMlA\nCtAaKA4MBdYAf/rxJfz0lXGJbBuwBZiVRTzPA78DO4DvgPOCxp3lh+3w6xiayTIq+vVt8uubBByX\nybQzgIPAXr8PGvjtviFommuBL4M+pwO3ACuArcDL2e1T4G0gDdjth9+LO5CnAwl+vurABB/zCuDG\noGUOAMYBI/38i4FmWezHc4F5fp/PBc4J+u4O4E4idgKtQ8x7OTDf7+c1wIAs1nMB8HuGYRuBfwR9\nbghM89u1DLgqaFwl//3s8HE+EdjXGfePH3bou/Hfy+wwfzsDgPeBd4DtwA1+2Nt+/Eu43/JO/zcV\neNSPewD4Jej77By0XXv9tCn4/zW/jx/P8HtYiTuIfQxUD/e3lGG/BrZhrI/le+DUoPEh4wzaV18B\nz/o4Hgfq437/m3H/K6OA8kHzrML9Thf57XsDOBb41K9jGlAhaPoWwNe439wC4AI//Enc/9geP9+L\nYfwu/naMCbE/ZgLnA48GfVc34o4NpbLYj78BtYG3gF65OrbmZqaC9gLKAX8BI4C2QMUM468C1uIP\nRP4HVQso6n/wD/j3F/ov/oSgL3cb0MJ/LgE85/85KgBlcAfCp/z4//gfQwJQBGiZRcw9cAkgAbjL\n/xiK+3HfAD39+9JA80yWUQm4wsdVBnfgHZ/FOjMmjFAJJPhAlQ5M9Pu3lv/nuySrfRr0D3lh0HLq\n4JJKIIHMxh3IigGn+eUm+XED/D/gpbiz3v8A32ayPYm4g1EPvx+7+c+JQd/f41nsj/OBk/37Jv47\n6JjJtIcSiI+rI+5gcVrQ9/Q70MuPPw33m2zox48FRvvvqpGfdnao/ZPxuwnxvWT12xmAS5od/OeS\nBCWQDNt0Gi4Jnuo//wOoGvT97gr6fEQMGfcv7uTqL7/MYsCLBJ1AZfVbChFXYBuuwP0f3YM7GBYJ\nM85U4N9+/5QAjgcuwv2PVwaSgWeD1rcK9z9XBXdysxGftHAnjDOA/n7aGrhEdKn/fJH/XDmT/6ns\nfhcZjzHFwzzmjQGGR/pYmvFV0ItcwqKqKcB5uB/p68AmEZkgIsf4SXoDQ1R1vp/+N1VdizuTKKOq\ng1X1oKp+AXwCdA9a/ARVnePn2487y7pLVXeo6m5gUND0qbgfYD1VTVPVr7OIebSqblfVdFV9DvdD\nP8mPPgA0EJHKqrpHVedlsoytqvqRqu73sTyNO9BF0tOqmuL31xe4qwzIfJ8GhKwwF5FauEvtB1Q1\nVVUXAcNw/2ABX6nqZ+r+U97B/SOH0g5Y4fdluqqOBX4GOoSzYao6W1WX+Pc/4Q7yWe2/GiKyFXc2\n/iFwt48foD2wSlXfVmeRn+YqXyzRBXf2uF9Vl+GusHIlm98OuIQ7yU+7L9Qy/P/Gx8Btqvqjn/ZD\nVd3o37+PO7kKtzikB/Cmqi5S1VTgQeAcEakdNE1mv6VQfvC/7TTc1URJ3P9rOHGuU9VX/P7Zr6q/\nquoM/z++BXcSmPF7fklVN6vqn8CXwFxV/VFVDwAfAaf76XoCk1X1M7/+Gbhkc3km25Hp7yJomuBj\nzIEs9kmwyrgTh6g6KhIIgKouV9UbVLU27mzyONylPrgznl9DzHYc7iw62BrcWUbAofH+n6408IOI\nbPUHkym4LxPgGb+eaSLyi4g8kFm8InKviCwVkW0isg0ojzsDAndwPgn4WUTmiki7TJZRSkReE5HV\nIrIdmAVUjHBrp41B7/cAZf37zPZpdqrjikD2BA3LuM83ZFhnyUzKho/z8wbLuKxMiUhzEZkpIpv8\n/ruFw99BKOtUtRLuLPpF3Fl3QB2gReB34b/THkBV4Bjc2e8fQdNn/N2FLZvfTrbLFpGiuCKiUf4A\nHBjey7fSCyz3ZLLeH8GO+C78Cc0WjvwuMvsthXJoG/yJxB9+HeHEecT2+9Z4Y0TkD/89jwqxXcGx\n7Q3xORBrHaBrhu+5JVAtk+3I6ncRMt4wbcH9L0XVUZNAgqnqClxxVhM/aC3uMjaj9bgDYbDawLrg\nxQW934z74Z+sqpX8q6K6SlVUdZeq3quqx+OKOO4WkQszrlREzgPuA65U1URVTcQVnYlfzq+q2kNV\njwGGAB+ISKkQ8d8DnACcpaoVcUUykMnZfwi7cQkxILN/glAy26eQdWXreqCSiJQJGpZxn4drPVA3\nw7CcLGs07iy8ht9/rxHGvvNn2P2AU0Wkox+8FkgO+l0kqqtwvw1XZJEK1AxaTPDvbrf/m+13ISKt\nyOK3Ewgxm014Cdiuqv2Dllsbd/X+76DlLglabnbLXI87WAaWVwZ3YvVHpnNk7dD+8SdENYH1YcQZ\nKtb/4EonTvbf8zWE/z+S0VpccWDw91xOVQPNxDOuO6vfRWbxhuNz4NJMjgsRc1QkEBE5SUTuFpEa\n/nMtXLHSt36SYcC9ItLMjz/eTzMX2CMi94tIURFJwl1yjgm1Hn8m9AbwfKB4TERqiMgl/n07EQkc\nVFNwZeTpIRZVDndA2SIixX3TvHJB29NTRAJnSDtwP7DMlrMX2Omb7g3Maj+FsBDo4q9kGuCufMKV\n2T4Fd/ZWP8P0geT4B668+WkRKSEip/r1vpPFujL7Z/8UOEFEuolIERG5Gle/8EmY21AW2KaqqSLS\nHHdmGBafRP6LK6/Hr/NEEbnG/5aKiciZInKSqqYD44GBfl83JKjITlU345LeNSKSIK4ZaGbJuSxZ\n/HayIyK34IpvrskwqgzuN7bZx3A9h0/AwH2nNX3rn1DGANeLyKkiUgJ30J6ToVgzJ84Qkc6+FdVd\nwD5gThhxhlIOV0+S4o8ReWnSPQroICKX+PWXFNfE+zg/PuNvP9PfRR5iAPf/shb40B//REQqi7vn\np20el33IUZFAcAfrs4G5IpKCO0D9iGtZgap+ADwFjBaRnbgyzUr+INABV365GXgZ+KeqrvTLDXVm\nEGgBMsdfDk8DTvTjTgA+9zF8DfxPVWeFWMZn/rUCV4G3hyMvY9sCS3yszwFXq6t/yeh53FnrZr/N\nn2a6h0Jvz3O4g9EGXGXeqGymP/Q5s33qRz8N9PeX7HeHWFZ3oB7urPVDXAXlFzmIOxDDVlzCvxe3\nD+4F2vnhmc4X5N/AEyKyA3gE1wghJ94CaolIO1XdBVyCq8hf71+DcPUTAH1xFd9/4uo/RnNkM/Ob\ncPfpbMYlwczqz7L77WSnG37fi0iKuPsH+vl6mWdxB+kNuGKhr4Lmm4k7098gIpsyLtTXBfTHJcp1\nfh3dgifJOEs2cU4ArsZVMPcErlBXr7gMl7gzizOUx3AtNbfjWsJ9mE0smcbmT4A6AQ/hrizX4H53\ngWPtC7h6ry0i8nwYv4tc8XUlF+Pq/KbjTjTn4K765uZl2cHEnTRHj892z+N24JuqOjjD+Iq4f7Tj\ncWfLN6jqUj9uNW7D04FUVW3uhyfi/pnrAKuBrqq6I6obYkw+EpFBuJZD18c6lngjIgOA41U1Vze/\nmciJ6hWIuIrNl3FNLk8GuvvL82APAQtU9TRcE7sXg8al45pvnh5IHl4/4HNVPQl35vNgtLbBmPzg\nixlO8e+b44rtxsc2KmOyFu0irObASlVd44uDxuIu74I1xiUBVHU5UFcON6+VTGLsxOFmjiOBzpEO\n3Jh8Vg4YLyK7cPUFzwSa2hoTr4pGefk1OLL89Q/+3m58Ea4N/Nf+zKs2rkXFX7iyxukikga8rqpv\n+HmODWrnvUFEjo3iNhgTdar6Pa6OzGRDVR+LdQzGiXYCCccg4AURmY/rlmIB7q5bcHdq/+mvSKaL\nyDJVDVUhFt2KHGOMMX8T7QSyDndFEVCTDG3w1d0lfqh3ShFZheuWAH/XJ6r6l4h8hLt6+QrYKCJV\nVXWjiFTDdXvwNyJiicUYY3JBVbO9FybadSDf4brcqCMixXFN1SYGTyAiFQJtx0XkJlz/OLtEpLSI\nlPXDy+Cauv3kZ5sIXOffX4tr0heSRrkvmGi+BgwYEPMYjtb4C3LsFn/sXwU9/nBF9QpEVdPEPZho\nGoeb8S7zNyupqr6Oa9M+UkTSce3IAzerVQU+8lcRRYF3VXWaHzcYeM/fULUG6BrN7TDGGPN3Ua8D\nUdWpHNmRG6r6WtD7ORnH++GryKQzNXU3gl0c2UiNMcbkxNFyJ3qBlJSUFOsQ8qQgx1+QYweLP9YK\nevzhivqd6LEkIlqYt88YY6JBRNAwKtHjoRmvMcZERd26dVmzJmOP/iagTp06rF69Otfz2xWIMabQ\n8mfSsQ4jbmW2f8K9ArE6EGOMMbliCcQYY0yuWAIxxhiTK5ZAjDGmgLr11lt56qmnYrZ+q0Q3xhRa\n8V6JXq9ePd58801at24dk/VbJboxxhRCaWlp2U8UY5ZAjDEmBnr16sXvv/9O+/btKV++PM888wwJ\nCQm89dZb1KlTh4suugiArl27Ur16dRITE0lKSmLp0qWHlnH99dfz6KOPAjBr1ixq1arFs88+S9Wq\nValRowYjRoyI6jZYAjHGmBh4++23qV27NpMnT2bnzp107er6hJ09ezY///wzn332GQCXX345v/76\nK5s2baJZs2b07Nkz02Vu2LCBlJQU1q9fz7Bhw+jTpw87duyI2jZYAjHGHNVEIvPKreA6CBHhscce\no1SpUpQoUQKA6667jtKlS1OsWDEeffRRFi1aREpKSshlFS9enP79+1OkSBEuu+wyypYty/Lly3Mf\nXDYsgRhjjmqqkXlFSs2aNQ+9T09Pp1+/fjRo0ICKFStSr149RITNmzeHnLdy5cokJBw+rJcuXZpd\nu3ZFLrgMLIEYY0yMSIhLl+Bho0ePZtKkScycOZPt27ezevXqHD/0KZosgRhjTIxUq1aN3377DSBk\nYkhJSaFEiRIkJiaye/duHnzwwZBJJ1YsgRhjTIz069ePJ554gkqVKvHhhx/+LTn06tWL2rVrU6NG\nDZo0acK5556bo+VHO9nYjYTGmEIr3m8kjDW7kdAYY0xM2AOlTIG0fz/4Vo4F0qZNcPBgrKPIvYoV\noXTpWEdhomHTpvCntQRiCpxff4VTT4UePeA//4Fjjol1ROFbtQruvhtmzoQyZWIdTe6lpcHjj8ON\nN0KRIrGOxkRCaiq89JL7nwqX1YGYAufKK+GEE2DfPnj3XRgwAG65BYrG8enQ3r0wZAi8+CLcdRfc\ney+ULBnrqHJv0SK47TbYswdefhnOOSfWEYVmdSBZC+yfGTOgb1+oVcv9Rhs2DK8OxBKIKVC+/BKu\nuQZ+/hlKlYKffoLbb4ctW9yBrFWrWEd4JFWYMMEljTPPhP/+F2rXjnVUkaEKo0fD/ffDJZfAoEFQ\ntWqsozqSJZCsiQhXXql8/z089xx06hS4s94q0U0hk57uin8GDXLJA6BJE5gxAx5+2BVpXXMNrF8f\n2zgDli+Hyy6Dhx6CYcPg/fcLT/IAd6Dp2dMl82OOcd/F88+7ohBTcDRpAkuXQufOOe+SxRKIKTBG\nj3bl7d26HTlcBLp2hWXL3AH61FPhmWfgwIHYxJmSAg88AC1bujPzRYvAd6xaKJUr54rnvvwSPv0U\nTj8dvvgi1lGZcA0YcPiELKesCMsUCHv2QMOGMHYsZHcv1cqVcMcd8Ntvrjz3kkvyJ0ZVGDPGFelc\ndJG7UqpePX/WHS9U4eOPXZHd2WfD0KGuXD1WrAgra3YfiDkqPPusq6gN50bcE06AyZPdVcitt0KX\nLrB6dXTj+/FHSEpy6xw3DkaOPPqSB7irwSuucEUiDRu6q5H//Mc1uzaFjyUQE/f+/NOVrQ8aFP48\nItChAyxZAs2awRlnuGane/dGNrZt21wl/sUXu6K17793RVdHu9Kl4bHHYN4892rSxBVvmSPVq1eP\nmTNn5mkZI0eOpFWMWo9EPYGISFsR+VlEVojIAyHGVxSR8SKySETmiEjjDOMTRGS+iEwMGjZARP7w\nw+eLSNtob4eJnf79oXdvqFcv5/OWLAmPPALz57urhJNPdq2i8lqqkZ4Ob74JjRq5upalS93Vjt0T\ncaT69V2R1osvwp13QseO7j4eEzmqGrsOFgM9QEbjhUtQvwB1gGLAQqBhhmmGAP39+5OAzzOMvwsY\nBUwMGjYAuDuM9asp2BYuVK1aVXX79sgsb/p01YYNVdu2VV2+PHfLmDtX9ayzVFu0UP3++8jEdTTY\nt0910CDVypVVH3lEdffu6K8zno8B//znPzUhIUFLly6t5cqV02eeeUbnzJmj5557rlasWFGbNm2q\nycnJh6YfPny41q9fX8uVK6f169fX0aNH67Jly7RkyZJatGhRLVu2rCYmJuYohsz2jx+e/TE+nIly\n+wJaAFOCPvcDHsgwzSdAy6DPvwDH+Pc1gelAUogEck8Y68/RzjTxJT1dtXVr1Vdeiexy9+9XHTrU\nHcgeeEA1JSW8+TZtUu3dW7VaNdURI1TT0iIb19Fi7VrVbt1Ua9dWff999z1HS7wfA+rWraszZ85U\nVdV169Zp5cqVderUqaqq+vnnn2vlypV18+bNunv3bi1fvryuXLlSVVU3bNigS5cuVVXVESNGaKtW\nrXK1/rwmkGgXYdUA1gZ9/sMPC7YI6AIgIs2B2rjEAfAccB8QqsDhNhFZKCLDRKRCRKM2cWHyZFf/\ncdNNkV1u8eJwzz2weLG7Z6RRI9e6K7NirYMH3U2KjRtD+fLuvodrr4UEq0HMlZo1XWu1kSNdPUmb\nNq4IMGZi/Exb9T+8UaNG0a5dOy699FIALrroIs4880w+9ZVHRYoUYfHixezbt4+qVavSqFGjvG97\nHsXDv8AgIFFE5gN9gAVAmoi0Azaq6kJA/CvgFaC+qjYFNgDP5nPMJspSU113H//9b/S6KKleHd5+\n2yWPwYPhwgtdPUmw2bNdJfz48ZCc7FqDVbDTlYhISoIFC1y9yAUXuO97584YBKLx8UzbNWvW8N57\n71GpUiUqVapEYmIiX3/9NX/++SelS5dm3LhxvPrqq1SvXp0OHTpE9Vnn4Yp270HrcFcUATX9sENU\nNQW4IfBZRH4DfgO6AR1F5HKgFFBORN5W1V6q+lfQIt4AJmUWwMCBAw+9T0pKIikpKbfbYvLRa69B\nnTrQNh+aR7Rs6VpPvf764dZU//oXPPWUuzlu6FC46qo8nWSaTBQt6lqxdesGDz7omv4OHux6FDga\n9ndw5XetWrXo1asXr732Wshp27RpQ5s2bdi/fz8PP/wwN998M7NmzYpIBXpycjLJyck5nzGccq7c\nvoAiHK5EL46rRG+UYZoKQDH//iZgRIjlXMCRdSDVgt7fBYzOZP25Khc0sbV1q+qxx6r++GP+r/uv\nv1Rvvlm1ZEnVhx5S3bUr/2M4ms2Zo3rmmarlyqkmJub9Fe/HgHPOOUffeOMNVVVdu3atVq9eXT/7\n7DNNS0vTvXv3anJysq5bt043btyoEyZM0N27d2taWpoOGDBAk5KSVFV16tSpWq9ePT1w4ECO15/Z\n/iHMOpCo34num9i+gCsue1NVB4nILT7A10WkBTASSAeWAL1VdUeGZVyAqzTv6D+/DTT186wGblHV\njSHWrdHePhN5997rugPJ5ETMFHKq7v6aSKhcOb7vRJ84cSJ9+/YlJSWFRx55hFatWnHfffexePFi\nihYtSvPmzXn11VcpWrQo3bp1Y9GiRYgITZs25ZVXXqFhw4akpqbSpUsXvvnmG4oUKcKmHDzQI693\noltXJiau/Pqr6wJjyZL469nVFDzWlUnWrCsTU6g88IBrIWXJw5j4F8eP4DFHmy+/hO++g3feiXUk\nxphw2BWIiQuhnvVhjIlvlkBMXMjsWR/GmPhllegm5nLyrA9jcsIq0bNmleimwHv2WWjRwpKHMQWN\nXYGYmPrzT/esiO++c11/GxNJdgWSNbsPJAuWQOLfjTdCpUrumdrGRJolkKxZEZYpsBYtgkmT4KGH\nYh2JMQXHrFmzqBXLB80HsQRiYkLVNdsdMAAqVox1NMYULDF7AmEGlkBMTASe9XHzzbGOxBiTW5ZA\nTL4LPOtj6NDoPevDmHg3ZMgQrrrqqiOG3Xnnndx5552MGDGCxo0bU758eRo0aMDrr78eoyizZgnE\n5LvXXoPateGyy2IdiTGx061bN6ZMmcLu3bsBSE9P57333qNHjx5UrVqVyZMns3PnToYPH85dd93F\nwoULYxzx39n5n8lX27bBE0/A558fHQ8MMvFPHovMD1EH5Ky1V+3atWnWrBkfffQR11xzDTNmzKBM\nmTI0b978iOlatWrFJZdcwpdffknTpk0jEmukWAIx+eqpp6BTJzjllFhHYoyT0wN/JHXv3p0xY8Zw\nzTXXMGbMGHr06AHAlClTePzxx1mxYgXp6ens3buXU089NWZxZsYSiMk3v/4KI0bATz/FOhJj4sNV\nV13Fvffey7p16/joo4+YO3cuBw4c4Morr2TUqFF06tSJhIQErrjiiri8n8XqQEy+eeAB13S3WrVY\nR2JMfKhSpQoXXHAB119/PfXr1+fEE0/kwIEDHDhwgCpVqpCQkMCUKVOYNm1arEMNyRKIyReBZ33c\ndVesIzEmvvTo0YMZM2bQs2dPAMqWLcuLL77IVVddRaVKlRg7diydOnWKcZShWVcmubVkCWz822PY\nTYAIVKgAlSuTnliZs1uX4a67BV/Ea0y+sK5MsmZ9YWUhqgnk6adh+vToLLswSE+HHTtgyxYObtxC\neupBilWrjFSu7Dq/qlw5+1elSnajiMkTSyBZswSSBetMMfb27IGTToJxI/dx7klbYEsOXtu3Q9my\noZPLccfBddfZw9NNliyBZC2vCcRO70xUPfssnHMOnNu6JFADatQIf+b0dJdEtm79e3JZtgwaN4Zb\nboH77oPExKhtgzEmNLsCMVET9Wd9/P67uyvxo4/gjjvgzjuhXLkorMgUVHYFkjXrzt3Erf79oXfv\nKD4oqnZteOMN+PZb+PlnaNAA/vtf2Ls3Sis0xgSzKxATFYsWwSWXwPLl+dhd+08/waOPwrx58PDD\nLnsVL55PKzfxyK5AsmaV6FmIZgIZMcIdp0xoX34Jt94K//53DFb+/ffwyCOwYoV74EjPntaa6yhV\nt25d1qxZE+sw4ladOnVYvXr134ZbAiG6CeTzz93xyYRWpkwcHLe//NJdifz1Fzz2GFx5JSRYqa0x\n2bEEghVhGdyjD6dNc1ckBw+6Svd27awrYGOyYAkESyAmiCpMmOBq9suWdd0Ct24d66iMiUtx0wpL\nRNqKyM8iskJEHggxvqKIjBeRRSIyR0QaZxifICLzRWRi0LBEEZkmIstF5DMRqRDt7TAFnAh07gwL\nF0Lfvu7+kYsuci24jDG5EtUEIiIJwMvApcDJQHcRaZhhsoeABap6GnAt8GKG8XcASzMM6wd8rqon\nATOBByMduymkihSBHj1g6VLo3h2uvhrat3eJxRiTI9G+AmkOrFTVNaqaCowFMnYr2RiXBFDV5UBd\nETkGQERqApcDwzLM0wkY6d+PBDpHJ3xTaBUrBjfeCCtXuvbGl10GXbu6+0mMMWGJdgKpAawN+vyH\nHxZsEdAFQESaA7WBmn7cc8B9QMaKjGNVdSOAqm4Ajo1s2OaoUaIE3H47/PILnHEGnH++62NrxQpI\nS4t1dMbEtXhoHD8IeEFE5gOLgQVAmoi0Azaq6kIRSQKyqtDJtKZ84MCBh94nJSWRlJQUgZBNoVOm\njHvi1b/+5TrwOu881weX75I+R69SpWK9NcbkSHJyMsnJyTmeL6qtsESkBTBQVdv6z/0AVdXBWczz\nG3Aqrm7kGuAgUAooB4xX1V4isgxIUtWNIlIN+EJVG4VYlrXCMrl38CBs25azHoS3bHH1LNklmQoV\nCvY9KcWLH9ktf/ny1jQ6P6Sluc7l/vorqquRjh1j34xXRIoAy4GLgD+BeUB3VV0WNE0FYI+qporI\nTUBLVb0uw3IuAO5R1Y7+82Bgq6oO9i27ElW1X4j1WwIx+UvV9WGfXZLZscNNW1Dt339kL8l794b/\nnJfg571YVzPZ277d3cv0yScwZYp7JnTdulFdpXzySewTCLhmvMALuPqWN1V1kIjcgrsSed1fpYwE\n0oElQG9V3ZFhGRkTSCXgPaAWsAboqqrbQ6zbEogx+eHAgdDd7mf12roVSpYMnVzKlo3uFU21au45\nA02bxmcSW7HCJYxPPnFd87Rq5VoLtmvnOhGNMruREEsgxsQ1Vdi5M3Ry2b07uuv9/Xd3D9Cvv7ok\ncs45h1/Vq0dv3Zk5cMB1vRNIGnv2uITRvr274bVMmXwNxxIIlkCMMdlISXG9on77rXvNmeOeKdOi\nxeGEEq2rlE2bXJHUJ5+4x2M3bOiuMNq3d+uMYZ2SJRAsgRhjckjVFR8Fkkkkr1JU4ccfD19lLFsG\nF1/sEsb5JzX4AAAgAElEQVRll8XV45ktgWAJxBgTAZldpQQnlNNOC32VsmcPzJzpEsbkyW6aDh1c\n0mjVyt2HFIcinkBEpBRQ298tXiBYAjHGRFzwVUrg9dtvR16lbNrkksbs2e4G1UDR1EknFYjmzhFN\nICLSARgKFFfVeiLSFHg80CoqXlkCMcbki5073f0ZgSuUihXdlcYll0BiYqyjy7FIJ5AfgNZAsqqe\n7octVtVT8hxpFFkCMcaYnIt0d+6pGe/NIIvuQ4wxxhR+4faFtUREegBFROQE4Hbgm+iFZYwxJt6F\newXSF/c8j/3AaGAHcGe0gjLGGBP/rBmvMcaYI0S0DkREpotIxaDPiSLyWV4CNMYYU7CFW4RVJbiz\nQlXdhj3EyRhjjmrhJpB0ETnUBaSI1MFaYRljzFEt3FZYDwNficgs3JMBWwE3Ry0qY4wxcS8nXZlU\nAVr4j3NUdXPUoooQq0Q3xpicC7cSPSfPRC8BbPXzNPYrmJ3bAI0xxhRsYSUQ/wjZq3FPDEz3gxWw\nBGKMMUepcPvCWg6cqqr7ox9S5FgRljHG5Fyk+8L6DSiWt5CMMcYUJuHWgewBForIDFx3JgCo6u1R\nicoYY0zcCzeBTPQvY4wxBrC+sIwxxmQQ0Wa8vgv3p4HGQMnAcFWtn+sIjTHGFGjhVqIPB14FDgIX\nAm8Do6IVlDHGmPgXbgIppaozcEVea1R1INAuemEZY4yJd+FWou8XkQRgpYjcBqwDykYvLGOMMfEu\n3BsJzwKWARWBJ4AKwBBVnRPd8PLGKtGNMSbnwq1Et1ZYxhhjjhDpJxKeKSIfich8Efkx8Apz3rYi\n8rOIrBCRB0KMrygi40VkkYjMEZHGfngJEZkrIgtEZLGIDAiaZ4CI/OHjmS8ibcOJxRhjTOTkpC+s\n+4DFHO5MEVVdk818CcAK4CJgPfAd0E1Vfw6aZgiQoqpPiMhJwP9U9WI/rrSq7hGRIsDXwO2qOs8n\nkxRVfTab9dsViDHG5FCku3P/S1Vzcyd6c2BlINGIyFigE/Bz0DSNcfeYoKrLRaSuiByjqn+p6h4/\nTQkfa3A2yHbjjDHGRE+4zXgHiMgwEekuIl0CrzDmqwGsDfr8hx8WbBHQBUBEmgO1gZr+c4KILAA2\nANNV9bug+W4TkYU+rgphbocxxpgICfcK5HqgIa5H3uDngYyPQAyDgBdEZD6uiGwBkAagqunA6SJS\nHvhYRBqr6lLgFeBxVVUReRJ4FugdauEDBw489D4pKYmkpKQIhGyMMYVHcnIyycnJOZ4v7DoQVT0p\nxwsXaQEMVNW2/nM/QFV1cBbzrAJOUdVdGYb3B3ZnrPcQkTrAJFU9NcSyrA7EGGNyKNLPA/km0Doq\nh74DGohIHREpDnQjQ6++IlJBRIr59zcBs1R1l4hUCRRNiUgpoA2+7kREqgUtogvwUy5iM8YYkwfh\nFmG1wD0PZBXueSCCu5L421l/MFVN83euT8MlqzdVdZmI3OLnfx1oBIwUkXTcI3MDRVHV/fAEP+84\nVf3UjxsiIk1xxWmrgVvC3A5jjDEREm4RVp1Qw7NrxhtrVoRljDE5F7E70f09GEtUtWGkgssvlkCM\nMSbnIlYHoqppwHIRqR2RyIwxxhQK4daBJAJLRGQesDswUFU7RiUqY4wxcS/cBNI/qlEYY4wpcMLu\njVdEqgJn+Y/zVHVT1KKKEKsDMcaYnIt0b7xdgXnAVUBXYK6IXJm3EI0xxhRk4TbjXQS0CVx1iMgx\nwOeqelqU48sTuwIxxpici3RvvAkZiqy2EP5d7IVS30/78uGyD2MdxlGrfInyfNztYxpWKXCty40p\nNMK9AnkGOBUY4wddDfyoqn97QFQ8ieYVyLa929h7cG9Ulm2yN2n5JJ755hnm3DiHKqWrxDocYwqV\niNxIKCIlVHW/f98FOM+P+lJVP4pIpFFkRViFW7/P+/HN2m+Y/s/plChaItbhGFNoRCqBzFfVZiLy\njqr+M6IR5gNLIIVbuqbzj/f+QYUSFRjeaTgi9owxYyIhUq2wiotID+Dc4AdJ5eCBUsZETYIkMOqK\nUfy48UeGfD0k1uEYc9TJrhL9X0BPoCLQIcO4SD1QyphcK1O8DJO6T+LsYWdzQuUT6NLIzmuMyS/h\ndKaYADyoqk/lT0iRY0VYR48f1v9A23fbMrXnVM447oxYh2NMgRbJzhTTAbtp0MS1M447g9fav0bn\ncZ1Zt3NdrMMx5qgQ7r0cM0TkH2K1lCaOdWnUhT5n9aHj2I7sPrA7+xmMMXkS7n0gKUAZIA3Yy+En\nEpaPbnh5Y0VYRx9V5foJ17Nz/04+6PoBCXJU3+9qTK5E7IFSBZklkKPT/oP7afNOG1rWasnTFz8d\n63CMKXAi3ZmiiMg1ItLff64lIs3zGqQx0VCiaAnGXz2e95a+x4iFI2IdjjGFVrhFWK8C6UBrVW0k\nIonANFU9K5tZY8quQI5uy/5axgUjLuCDrh9wfp3zYx2OMQVGRK9AgLNVtQ+wD0BVtwHF8xCfMVHX\n6JhGvNvlXbq+35Vftv4S63CMKXTCTSCpIlIEd/NgoDv39KhFZUyEtDm+DQOTBtJ+dHu27d0W63CM\nKVTCTSAvAh8Bx4rIU8BXwH+iFpUxEfSvM/9F2wZt6fpBV1LTUmMdjjGFRk4eadsQuAjXhHeGqi6L\nZmCRYHUgJiAtPY2OYztSq3wtXm33qnW8aEwWItUbb0lcf1gNgMXAm6p6MGJRRpklEBNs5/6dtHyr\nJTeefiN3tLgj1uEYE7ciVYk+EjgTlzwuA4ZGIDZjYqJ8ifJM6j6JwV8PZvKKybEOx5gCL7srkMWq\neop/XxSYp6rN8iu4vLIrEBPKt2u/pdPYTszoNYNTqp4S63CMiTuRugI5VONYkIqujMnKObXO4YW2\nL9BhTAc27toY63CMKbCySyCnichO/0oBTg28F5Gd4axARNqKyM8iskJE/vYMdRGpKCLjRWSRiMwR\nkcZ+eAkRmSsiC0RksYgMCJonUUSmichyEflMRCrkZKON6X5Kd65reh2dx3Vmb6o9296Y3IhqX1j+\nWSIrcK231gPfAd1U9eegaYYAKar6hIicBPxPVS/240qr6h5/D8rXwO2qOk9EBgNbVHWIT0qJqtov\nxPqtCMtkSlXpMb4HAKO7jLaWWcZ4kb4TPbeaAytVdY2qpgJjgU4ZpmkMzARQ1eVAXX+jIqq6x09T\nAvf0xEA26ISr4Mf/7Ry1LTCFlojwVse3WLVtFY/PejzW4RhT4EQ7gdQA1gZ9/sMPC7YI6ALgO2is\nDdT0nxNEZAGwAZiuqt/5eY5V1Y0AqroBODZqW2AKtVLFSvFxt48ZvnA4YxaPiXU4xhQo2T0TPT8M\nAl4Qkfm45sILcM8dCTwN8XQRKQ98LCKNVXVpiGVkWk41cODAQ++TkpJISkqKXOSmUKhWthoTu0/k\n4rcvpl5iPVrUbBHrkIzJV8nJySQnJ+d4vmjXgbQABqpqW/+5H+5BVIOzmGcVcIqq7sowvD+wW1Wf\nFZFlQJKqbhSRasAXqtooxLKsDsSEbfKKydw06Sa+7f0tdSrWiXU4xsRMvNSBfAc0EJE6IlIc6AZM\nDJ5ARCqISDH//iZglqruEpEqgdZVIlIKaAMEKt8nAtf599cCE6K8HeYo0O7Edtzf8n7aj2nPzv1h\nNTI05qgW9ScSikhb4AVcsnpTVQeJyC24K5HX/VXKSFzvvkuA3qq6Q0RO8cMT/Gucqj7ll1kJeA+o\nBawBuqrq9hDrtisQkyOqyq2Tb2XtzrVM7DaRIglFYh2SMfnOHmmLJRCTO6lpqVz27mU0ObYJz7d9\nPtbhGJPv4qUIy5gCp1iRYrx/1ftM/WUq//f9/8U6HGPill2BGJOJX7b+wnlvnceoLqO4uP7FsQ7H\nmHxjVyDG5FGDSg0Yd+U4enzYg583/5z9DMYcZSyBGJOFC+pewOCLB9N+dHs279kc63CMiStWhGVM\nGPp93o9v1n7D9H9Op0TRErEOx5ioslZYWAIxkZOu6fzjvX9QoUQFhncabh0vmkLN6kCMiaAESWDU\nFaP4ceOPDPl6SKzDMSYuWAIxJkxlipdhUvdJvDTvJcYvGx/rcIyJOUsgxuRAjfI1mNBtArd8cgs/\nrP8h1uEYE1OWQIzJoTOOO4PX2r9G53GdWbdzXazDMSZmLIEYkwtdGnWhz1l96Di2I7sP7I51OMbE\nhLXCMiaXVJXrJ1zPzv07+aDrBySInY+ZwsGa8WIJxETf/oP7afNOG1rWasnTFz8d63AKhV+2/sKs\n1bOiuo6kukkcX+n4qK4jWub/OZ8qpatQu0LtqK3DEgiWQEz+2LxnM2cPO5v+5/fnuqbXxTqcAmvX\ngV08Nfsp3pj/Bu1ObEdRic4DU/el7ePLNV8y58Y5HFfuuKisI1oW/LmANu+0QVHubnE395x7DyWL\nloz4eiyBYAnE5J9lfy3jghEX8EHXDzi/zvmxDqdAUVXeW/Ie906/l6S6SQy5eAjVy1WP6jqfmv0U\nHy//mFnXzaJ0sdJRXVekrE9Zz9nDzua5S5/jjOpncPe0u1m8cTHPt32e9ie2j+i6LIFgCcTkr+m/\nTuefH/2Tr274igaVGsQ6nALhp00/0XdKX7bt3cbLl7/MebXPy5f1qiq9Pu7FvoP7GHfluLivv9qT\nuofzh59Pl0ZdeKjVQ4eGf/bLZ9w+9XZOqHQCz7d9PmK/O7sT3Zh81ub4NgxMGkj70e3ZtndbrMOJ\na9v3befOqXfSemRrrmp8FT/c/EO+JQ9wB8hhHYbxZ8qfPPrFo/m23txI13R6fdSLxsc05sHzHjxi\n3KUNLmXxrYs5v875tBjWgodnPJyvrQItgRgTQf8681+0bdCWrh90JTUtNdbhxJ10TWf4guE0+l8j\n9qbuZWmfpfz7rH/H5NHBJYqW4KOrP2L04tG8s+idfF9/uPrP7M+GXRt4o8MbIftgK16kOPe3vJ9F\n/1rEqu2raPS/Rry/5H3yo/TFirCMibC09DQ6ju1IrfK1eLXdq9bxovf9+u+57dPbAHj58pc587gz\nYxyRs2TTEi4ceSHjrx6fr1dB4Xh70ds8Nusx5vSewzFljglrnlmrZ9F3Sl+qlK7CS5e9xMnHnpzj\n9YZbhIWqFtqX2zxj8t+OfTu0yStN9Plvn491KDH31+6/9KaJN2m1odV0+ILhmpaeFuuQ/mbqyqla\nbWg1/XXrr7EO5ZDZq2frMUOO0SWbluR43tS0VH1xzotaZUgVvWvqXbp97/Ycze+PndkeY60Iy5go\nKF+iPJO6T2Lw14OZvGJyrMOJibT0NF757hUa/68xpYuVZlmfZVzX9Lq4rLC+tMGlPNLqEdqPbs+O\nfTtiHQ6/bv2Vq96/ineueIfGxzTO8fxFE4rS9+y+LPn3Enbu30nD/zVk5MKRpGt6ROO0Iixjoujb\ntd/SaWwnZvSawSlVT4l1OPnmq9+/ou+UvlQsWZGXLnuJJsc2iXVIYen7aV9WbF3B5B6TKZoQnftQ\nsrN933bOffNcbmt+G/8+698RWea8dfO47dPbKJpQlJcvf5lm1ZtlOb0148USiIkPYxaP4cEZDzL3\nxrlULVs11uFE1Z8pf3L/5/eTvDqZoW2G0vXkrgWqDuhg+kHaj25Pg0oNePnyl2Oy/svfvZyGVRry\n4mUvRnTZgQYMD898mM4NO/NU66eoXLpyyGmtGa8xcaL7Kd25rul1dB7Xmb2pe2MdTlQcSDvA0G+G\ncsqrp1CrfC2W9VnG1U2uLlDJA1zRz7grx/HF6i94eV7+JhBV5fYpt1MkoQjPXvpsxJefIAn0btab\nZX2WUSyhGI3+14hXv3uVtPS0XC/TrkCMyQeqSo/xPQAY3WV0gTuwZmX6r9O5fert1KtYj+fbPs+J\nlU+MdUh5tmrbKs5961yGdxpO2wZt82WdL819idd+eI2vb/iaCiUrRH19izYsou+UvqQcSOHly16m\nZe2Wh8ZZERaWQEx82Zu6lwtHXshlDS5jQNKAWIeTZ2u2r+GeafewYMMCnr/UdadRmBLj179/zRXj\nrmDmtTOjXoczZeUUbph4A9/c8A31EutFdV3BVJUxP43h/un307peawZfPJjq5apbAgFLICb+bNi1\ngRbDWnDfuffFzX0QuTHt12m8MPcF7jj7Du5reV9UOvSLB6N+HEX/L/oz98a5HFvm2Kis46dNP9F6\nZGs+7vYx59Y6NyrryE7K/hSenP0kby54k4daPcQ9595jCcQSiIlHP278kds+vY39aftjHUqunVDp\nBJ5q/RR1KtaJdShR139mf2aunsmMXjMinig37d7E2cPO5skLn6TnqT0juuzcWL55OXd+didTr5ka\nHwlERNoCz+Mq7N9U1cEZxlcE3gKOB/YCN6jqUhGpCbwNVAXSgTdU9UU/zwDgJmCTX8xDqjo1xLot\ngRhj8iRd0+n2QTeKFynOO1e8E7Fiun0H99F6ZGsurn8xj1/4eESWGSlxUYQlIgnACuAiYD3wHdBN\nVX8OmmYIkKKqT4jIScD/VPViEakGVFPVhSJSFvgB6KSqP/sEkqKqWTZVsARijImEPal7SBqRRMeT\nOvLI+Y/keXmqyjUfXcPB9IOM+ceYuLu5Ml6a8TYHVqrqGlVNBcYCnTJM0xiYCaCqy4G6InKMqm5Q\n1YV++C5gGVAjaL7CU1tnjIlrpYuVZkK3Cbz+w+u8t+S9PC/vydlP8svWXxjRaUTcJY+ciHbkNYC1\nQZ//4MgkALAI6AIgIs2B2kDN4AlEpC7QFJgbNPg2EVkoIsNEJPpt3owxR7Xq5aozsftE+nzah3nr\n5uV6OeN+GsewBcOY0G0CpYqVimCE+S8eUt8gIFFE5gN9gAXAoTtbfPHVB8Ad/koE4BWgvqo2BTYA\nkb/rxhhjMmharSlvdnyTK8Zdwe87fs/x/HP/mMttU25jYreJVCtbLQoR5q9od/ayDndFEVDTDztE\nVVOAGwKfRWQV8Jt/XxSXPN5R1QlB8/wVtIg3gEmZBTBw4MBD75OSkkhKSsr5VhhjjNfxpI6s3LKS\nDmM68NX1X1GuRLmw5vt9x+90ea8Lb3V8i9OqnRblKHMmOTmZ5OTkHM8X7Ur0IsByXCX6n8A8oLuq\nLguapgKwR1VTReQmoKWqXufHvQ1sVtW7Myy3mqpu8O/vAs5S1R4h1m+V6MaYiFNVbp50Mxt3b+Sj\nqz/K9oFYKftTOG/4eVx72rXcfc7dWU4bD+KiFZYPpC3wAoeb8Q4SkVtw/c2/LiItgJG4prpLgN6q\nukNEWgKzgcWA+tdDqjrVJ5amfp7VwC2qujHEui2BGGOi4kDaAdqOakuz6s0YesnQTKdLS0+j87jO\nVC9bndfav1Yg7taPmwQSS5ZAjDHRtHXv1kM9C9x0xk0hp7nns3tYuHEhU3tOpViRYvkcYe6Em0Bi\n0+G9McYUApVKVeKTHp/Qangrjq90PK3rtT5i/Os/vM4nKz9hTu85BSZ55EQ8tMIyxpgC68TKJzL2\nH2Pp/mF3VmxZcWj4jN9m0P+L/nzS/RMSSyXGMMLosSIsY4yJgGHzhzH468HM6T2HzXs2c/6I8xl3\n5TiS6ibFOrQcszoQLIEYY/LXfdPuY976eaxPWU+/lv3o3ax3rEPKFUsgWAIxxuSvtPQ0eo7vSYNK\nDXiy9ZOxDifXLIFgCcQYY3IjXjpTNMYYU0hZAjHGGJMrlkCMMcbkiiUQY4wxuWIJxBhjTK5YAjHG\nGJMrlkCMMcbkiiUQY4wxuWIJxBhjTK5YAjHGGJMrlkCMMcbkiiUQY4wxuWIJxBhjTK5YAjHGGJMr\nlkCMMcbkiiUQY4wxuWIJxBhjTK5YAjHGGJMrlkCMMcbkiiUQY4wxuWIJxBhjTK5YAjHGGJMrUU8g\nItJWRH4WkRUi8kCI8RVFZLyILBKROSLS2A+vKSIzRWSJiCwWkduD5kkUkWkislxEPhORCtHeDmOM\nMUeKagIRkQTgZeBS4GSgu4g0zDDZQ8ACVT0NuBZ40Q8/CNytqicD5wB9gubtB3yuqicBM4EHo7kd\nsZKcnBzrEPKkIMdfkGMHiz/WCnr84Yr2FUhzYKWqrlHVVGAs0CnDNI1xSQBVXQ7UFZFjVHWDqi70\nw3cBy4Aafp5OwEj/fiTQObqbERsF/UdYkOMvyLGDxR9rBT3+cEU7gdQA1gZ9/oPDSSBgEdAFQESa\nA7WBmsETiEhdoCkwxw86VlU3AqjqBuDYCMdtjDEmG/FQiT4ISBSR+UAfYAGQFhgpImWBD4A7VHV3\nJsvQqEdpjDHmCKIavWOviLQABqpqW/+5H6CqOjiLeVYBp6jqLhEpCnwCTFHVF4KmWQYkqepGEakG\nfKGqjUIsyxKLMcbkgqpKdtMUjXIM3wENRKQO8CfQDegePIFvQbVHVVNF5CZglq/zAHgLWBqcPLyJ\nwHXAYFzF+4RQKw9nBxhjjMmdqF6BgGvGC7yAKy57U1UHicgtuCuR1/1VykggHVgC9FbVHSLSEpgN\nLMYVUSnwkKpOFZFKwHtALWAN0FVVt0d1Q4wxxhwh6gnEGGNM4RQPlehRJSKnici3IrJAROaJyJmx\njimnRKSviCzzN1QOinU8OSUi94hIur9yLDBEZIjf7wtF5EMRKR/rmMKR3c278SyrG4gLChFJEJH5\nIjIx1rHklIhUEJH3/e9+iYicndX0hT6BAEOAAap6OjAAeCbG8eSIiCQBHXANC04BhsY2opwRkZpA\nG1xRY0EzDThZVZsCKykAN6yGefNuPMvqBuKC4g5gaayDyKUXgE99o6TTcPffZepoSCDpQKCrk4rA\nuhjGkhu3AoNU9SCAqm6OcTw59RxwX6yDyA1V/VxV0/3HOWS4PylOhXPzbtzK5gbiuOdPmC4HhsU6\nlpzyV9itVHU4gKoeVNWdWc1zNCSQu4ChIvI77mok7s8iMzgRON/3E/ZFQSqCE5GOwFpVXRzrWCLg\nBmBKrIMIQzg37xYIQTcQz41tJDkSOGEqiJXL9YDNIjLcF8G9LiKlspoh2s1484WITAeqBg/CfYEP\nAxfjbkL8WESuxDUNbpP/UWYui/gfwX1HiaraQkTOwrU+q5//UYaWTewPceS+jrtm1Vn9dlR1kp/m\nYSBVVUfHIMSjUoYbiHdlN308EJF2wEZVXeiLnuPu956NokAzoI+qfi8iz+P6HRyQ2QyFvhWWiGxX\n1YpBn3eoaoHpvVdEPgUGq+os//kX4GxV3RLbyLImIk2Az4E9uH+kmrjiw+aquimWseWEiFwH3AS0\nVtX9MQ4nW7m5eTfeZHYDcbwTkf8A1+DqcUoB5YDxqtorpoGFSUSqAt+qan3/+TzgAVXtkNk8R0MR\n1joRuQBARC4CVsQ4npz6GGgNICInAsXiPXkAqOpPqlpNVeuraj1cUcrpBSx5tMUVR3QsCMnDO3Tz\nrogUx928W9BaA2V2A3FcU9WHVLW2PwB3A2YWlOQB4PsXXOuPMwAXkU1jgEJRhJWNm4AXRaQIsA+4\nOcbx5NRw4C0RWQzsBwrMDzIDpeBd0r8EFAemiwjAHFX9d2xDypqqponIbbgWZIGbd7NsSRNP/A3E\nPYHFIrKAoBuIYxvZUeN24F0RKQb8Blyf1cSFvgjLGGNMdBwNRVjGGGOiwBKIMcaYXLEEYowxJlcs\ngRhjjMkVSyDGGGNyxRKIMcaYXLEEYnJERNJ8PzmLRWRCNLo4F5ELRGRSDuepLiLv5WJdFUTk1rwu\nJ5Nlf+G7VV8oIl+KyAmRWG5eici1/lHQeV1OJxF5xL9vJSI/iEiqiHQJsb4VIrJcRP52H5OIPCgi\nB0SkZ4hxl4nIdyLyk1/+M354HxHJ8h4FE32WQExO7VbVZr5r+W1AnyitJ+wblESkiKr+qapdc7Ge\nRODQzYF5WE5muvvu4N8mB13x+xtfo+U6ctjBYibx3A+84t+vwT1e+t0M8yUCjwJnAWcDA8Q9xjow\n/p/AJUBD4B7fW0RgXBPczZw9VLUJcCbwix/9FtA3J9tgIs8SiMmLbwk6EInIveIe2rVQRAYEDe/v\nz8Rni8hoEbnbD/9CRJr595VFZFXGFYjIWSLyjT/7/CpwFu/PaieIyAzgc991x2I/7g1xDxBbICKb\n/PrLiMjnIvK9iCwSkUD/Pk8D9f1V1eAMyykhIm+JyI9+/UlB6/5QRKb4s+qs+pkK3H0/Gzg+aH/M\n9cv9v6Bt/UJEnhORecDtItJeXC/MP4jINBE5xk83QERG+P25SkSu8LH/KCKfBg72ItJMRJL9GfwU\nEakmIv/AHYhH+W0uEWK6qqHiyfC9nADsU9WtAKr6u6r+xN8T/6XANFXd4R87PQ0I9NN1Ea7vqMtV\n9Tc/7UAROcXPex/wpKqu9OtQVX3Nv98LrJIC1Dt1YXQ0dGViIkvg0BnpRfjnHohIG+AEVW0uIgJM\nFNcZ2z7gCuAUoAQwH/g+k2WHuupYBpynqun+gPM0cKUfdzruQVs7RKROYH5VvcnHVBvXBfsIYC/Q\nWVV3iUhl3PM9JuF6Gz1ZVQOJ7NBycFdX6ap6qoicBEyTw8VQp+G6Gk8FlovIi6qa1bNmOgKBbu1f\nUtUn/PreFpF2qjrZjyumqs39uAqq2sK/74074w88W6U+kAQ0wSXyK1T1AREZD7QT1wnnS7h+vLaI\nSFfgKVXtLa6rk7tVdYG4jgszTvcfoHfGeDJoifsus5Oxe/l1fhiqOgOYERihqn8BrYKmbULWV20/\n+Okz+z2ZKLMEYnKqlIjMx/WuuxSY7odfArTx4wQoA5wAlAcm+IcbpUoO6zZwDwF72x+4lSN/s9NV\ndUeomUSkJPA+cJuqrvUHyqdF5HzcQ8aOE5Fjs1n3ecCLAKq6XERW457PAjAj0M24iCwF6hD6YWXv\nisheYDWHi1wuEpH7gNK4IrSfgEACGRc0by1x9THVgWJA8BXaFJ9UFwMJqjrND18M1AVOwh2Ap/uE\nngCsD95F/m920wXHE6w68Fcm4/LLJlz8JkYsgZic2qOqzfwB+jPcWfrLuAPS06r6RvDEInJHFss6\nyFaWZQAAAAKuSURBVOFi1JKZTPMErlfTLv7q4IugcbuzWParwAeqGpi+J1AF1yNwui8uy2ydmQnu\nDDK4d940Mv9f6qGqCw4tQKQE8D+gmaquF1fUFxxH8Da9BAxV1cniepQOfi7DfnDFOiKSGjQ83cci\nwE+q2jKMbcpqusz28V7cyUF21uGulAJqcuR3mJWfcMVtmT2QrKSPw8SI1YGYnBIAVd2He/bzveKe\nw/0ZcIOIlAEQkeN8mf3XQAdf1l4WaB+0rNW4AwTAVZmsrwKHz+zDanUjIn2Asqr6TIblbPLJ40Lc\nFQNACu65DaF8iUs8ga70awHLw4khOJwMn0virqS2+P1x5d9nOaQ8h68Grs3BOsDFeYy454MgIkVF\npLEft5PDB/+spsvKMtwVZnbxfIa7Mq0grkK9jR8WjqHAg3K43itBRG4JGn8iLsmYGLEEYnLqUD2F\nf3b1IlxLo+nAGOBbEfkRV3xUVlW/xz2PYhGumOZHIFDsNBS4VUR+ACplsr4hwCA/Tbi/13uAU8RV\nos8XkZtxrYPOEpFFuIrbZX4btgJf+wrojJXhrwBF/PaMAa71RXGZ7pPshvsitzeAJbj6mXlZTP8Y\n8IGIfEfWxUWh1pOKS06DRWQhsAA4x48eCfyfL25MwCXvUNNl1RJuNq4OCAAROVNE1v5/e3eIg0AU\nA2F4qpGcgBvgOQ9+OQACg8USLoBArkegQXIOFLqINgEFSZPlBfJ/epOaTSbz3mabM7d5tCZ3vyla\n5FmxmnaVl+kf5SrkTtLezK6Kd2fy8shMzyNUNMDv3DE4Mxu5+91iv/JJ0jzDBz/MzDaSenc/Npg9\nlbRw93fNDAOjgeAbdhbLgS6SDoTH31grPgRoYSxp2Wg2Eg0EAFBCAwEAlBAgAIASAgQAUEKAAABK\nCBAAQAkBAgAoeQBW5mLqxNmdhgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1199adfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#initialize some variables\n",
    "train_score = []\n",
    "val_score = []\n",
    "test_score = []\n",
    "Cs = []\n",
    "\n",
    "#tune regularization parameter\n",
    "for reg in range(-7, 7):\n",
    "    C = 10**reg\n",
    "    logreg = LogisticRegression(C=C)\n",
    "    logreg.fit(x_train, y_train)\n",
    "    Cs.append(reg)\n",
    "    train_score.append(logreg.score(x_train, y_train))\n",
    "    test_score.append(logreg.score(x_test, y_test))\n",
    "    val_score.append(logreg.score(x_val, y_val))\n",
    "\n",
    "#graph performance vs. reg parameters\n",
    "plt.plot(Cs, train_score, c='b', label='train')\n",
    "plt.plot(Cs, test_score, c='r', label='test')\n",
    "plt.plot(Cs, val_score, c='g', label='val')\n",
    "plt.xlabel('Regularization Parameter (10^C)')\n",
    "plt.ylabel('Performance')\n",
    "plt.title(\"Scores as a function of a Regularization parameter \\\"C\\\"\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see here is that our predictor performs best when C = .001. This is place where the test performance begins to decline, and the training performance begins to climb. This divergence is indicative that we have met the value of the tuning parameter that performs best without overfitting the noise in the training set.\n",
    "\n",
    "Let's see how our model performs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function will give us the specificity, sensitivity, false positive, and false negative\n",
    "#given predictions and actual datasets\n",
    "def get_stats(predict, actual):\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    false_pos = []\n",
    "    false_neg = []\n",
    "\n",
    "    for each in range(len(actual)):\n",
    "        if predict[each] == 1.0 and float(actual.iloc[each]) == 1.0:\n",
    "            specificity.append(0)\n",
    "            sensitivity.append(1)\n",
    "            false_pos.append(0)\n",
    "            false_neg.append(0)\n",
    "        if predict[each] == 1.0 and float(actual.iloc[each]) == 0.0:\n",
    "            specificity.append(0)\n",
    "            sensitivity.append(0)\n",
    "            false_pos.append(1)\n",
    "            false_neg.append(0)\n",
    "        if predict[each] == 0.0 and float(actual.iloc[each]) == 1.0:\n",
    "            specificity.append(0)\n",
    "            sensitivity.append(0)\n",
    "            false_pos.append(0)\n",
    "            false_neg.append(1)\n",
    "        if predict[each] == 0.0 and float(actual.iloc[each]) == 0.0:\n",
    "            specificity.append(1)\n",
    "            sensitivity.append(0)\n",
    "            false_pos.append(0)\n",
    "            false_neg.append(0)\n",
    "\n",
    "    sensitivity = round(np.sum(sensitivity)/float(np.sum(actual)), 3)\n",
    "    specificity = round(np.sum(specificity)/float((len(actual) - np.sum(actual))), 3)\n",
    "    false_pos = round((np.sum(false_pos)/float(len(actual) - np.sum(actual))), 3)\n",
    "    false_neg = round((np.sum(false_neg)/float(np.sum(actual))), 3)\n",
    "    \n",
    "    return sensitivity, specificity, false_pos, false_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sensitivity (True Positive) rate of the model is: 0.004\n",
      "The specificity (True Negative) rate of the model is: 0.999\n"
     ]
    }
   ],
   "source": [
    "#fit our best model\n",
    "best_logreg = LogisticRegression(C=(10**-3))\n",
    "best_logreg.fit(x_train, y_train)\n",
    "logreg_predict = best_logreg.predict(x_test)\n",
    "\n",
    "sensitivity, specificity, false_pos, false_neg = get_stats(logreg_predict, y_test)\n",
    "print \"The sensitivity (True Positive) rate of the model is:\", sensitivity\n",
    "print \"The specificity (True Negative) rate of the model is:\", specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Analysis and iteration\n",
    "As with most disease classification problems, we are trying to classify a pretty rare event (about 6% prevalence in our dataset). What happens in this instance is that our logistic regression is attempting to classify based on a 50/50 probability... as such it classifies EVERYTHING as a \"No Disease\". But what we have in actuality is about 94/6 probability. We'll need to build a custom classifier to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this is a function that does a logistic regression with a custom probability parameter\n",
    "def tune_specificity(x_test, y_test, prob):\n",
    "    cust_predict = []\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        exp = np.sum((x_test.iloc[i].values * best_logreg.coef_)) + best_logreg.intercept_\n",
    "        pred = 1 / (1 + math.exp(-exp))\n",
    "        if pred <= prob:\n",
    "            cust_predict.append(0)\n",
    "        else:\n",
    "            cust_predict.append(1)\n",
    "\n",
    "    ###\n",
    "    sensitivity, specificity, fp, fn = get_stats(cust_predict, y_test)\n",
    "\n",
    "    return sensitivity, specificity, fp, fn, cust_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEZCAYAAADCJLEQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njJDEDMowDMMISf4PccC2mq63NMcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11978b810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sens = []\n",
    "spec = []\n",
    "fps = []\n",
    "fns = []\n",
    "increments = []\n",
    "\n",
    "#tune our probabilities\n",
    "for each in range(1, 6):\n",
    "    log_prob = 0.01*each\n",
    "    sensitivity, specificity, fp, fn, predictions = tune_specificity(x_test, y_test, log_prob)\n",
    "    sens.append(sensitivity)\n",
    "    spec.append(specificity)\n",
    "    fps.append(fp)\n",
    "    fns.append(fn)\n",
    "    increments.append(log_prob)\n",
    "    \n",
    "#graph statistics based on probability tuning\n",
    "plt.plot(increments, sens, c='b', label='sensitivity')\n",
    "plt.plot(increments, spec, c='r', label='specificity')\n",
    "plt.plot(increments, fps, c='g', label='Type I')\n",
    "plt.plot(increments, fns, c='y', label='Type II')\n",
    "plt.xlabel('Probability values')\n",
    "plt.ylabel('Accuracy and error rates')\n",
    "plt.title(\"Accuracy and error rates as a function of a logistic probability score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- True Negative : True Positive-----\n",
      "--------------------------------------------------------\n",
      "At probability 0.01 -         0.316 : 0.791\n",
      "At probability 0.02 -         0.592 : 0.598\n",
      "At probability 0.03 -         0.738 : 0.414\n",
      "At probability 0.04 -         0.829 : 0.316\n",
      "At probability 0.05 -         0.881 : 0.275\n"
     ]
    }
   ],
   "source": [
    "print \"--------------------- True Negative : True Positive-----\"\n",
    "print \"--------------------------------------------------------\"\n",
    "\n",
    "for each in range(len(increments)):\n",
    "    print \"At probability\", increments[each], \"-        \", spec[each],\":\",sens[each]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- True Negative : True Positive---\n",
      "--------------------------------------------------------\n",
      "At probability 0.025 -         0.675 : 0.5\n"
     ]
    }
   ],
   "source": [
    "sensitivity, specificity, fp, fn, predictions = tune_specificity(x_test, y_test, 0.025)\n",
    "print \"--------------------- True Negative : True Positive---\"\n",
    "print \"--------------------------------------------------------\"\n",
    "print \"At probability 0.025 -        \", specificity,\":\",sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Iteration #2\n",
    "Wanting to see if we could do any better with a different model, I tried subsampling the data so we had an equal number of positive and negative responses. It didn't work very well, but you can see code and discussion in Appendix D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Iteration #3\n",
    "Nope. No better with subsampling. So we have a pretty good estimator here... VERY close to our benchmarks. Let's move forward with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flu_predict(x_test):\n",
    "    #drop duplicative/unnecessary columns\n",
    "    cols = [2,3,9,11,16,17,20,21,25,26,27,28,29,30,36,37,42,43,48,49,57,59]\n",
    "    x_test.drop(x_test.columns[cols],axis=1,inplace=True)\n",
    "\n",
    "    #fill blank entries\n",
    "    x_test.fillna(0, inplace=True)\n",
    "\n",
    "    # Create a new data frame to store one-hot encoding of attributes\n",
    "    flu_data_expanded = pd.DataFrame({}) \n",
    "\n",
    "    # Iterate over all attributes\n",
    "    for column in x_test.columns:\n",
    "        # Check if attribute is categorical: has less than 8 unique values,\n",
    "        # or is string values (column has type 'object')\n",
    "        if len(x_test[column].unique()) < 8 or x_test[column].dtype == np.dtype('object'):\n",
    "            # use one-hot encoding for this column\n",
    "            encoding = pd.get_dummies(x_test[column])\n",
    "            # append expanded attribute to data frame\n",
    "            flu_data_expanded = pd.concat([flu_data_expanded, encoding], axis=1)\n",
    "        else:\n",
    "            flu_data_expanded = pd.concat([flu_data_expanded, x_test[[column]]], axis=1)\n",
    "    \n",
    "    #fit our custom probability model\n",
    "    y_pred = []\n",
    "    for i in range(len(flu_data_expanded)):\n",
    "        exp = np.sum((flu_data_expanded.iloc[i].values * best_logreg.coef_)) + best_logreg.intercept_\n",
    "        pred = 1 / (1 + math.exp(-exp))\n",
    "        if pred <= 0.25:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "            \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flu_data2 = pd.read_csv('flu_test_no_y.csv', delimiter=',', header=0)\n",
    "\n",
    "predictions = flu_predict(flu_data2)\n",
    "ids = []\n",
    "for each in range(len(flu_data2)):\n",
    "    ids.append(flu_data2.iloc[each, 0])\n",
    "    \n",
    "#export a file\n",
    "with io.FileIO(\"preds.txt\", \"w\") as file:\n",
    "    file.write(\"index,label\\n\")\n",
    "    for each in range(1, (len(predictions)+1)):\n",
    "            file.write(str(ids[(each-1)]) + \",\" + str(predictions[(each-1)]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Diagnosing Strains of the Semian Flu\n",
    "\n",
    "From a public health perspective, we want to balance the cost of vaccinations, early interventions and the cost of treating flu complications of unvaccinated people. \n",
    "\n",
    "There are two different strains of the flu: strain 1 has a cheaper early intervention as well as a cheaper treatment for flu complications, but patients with strain 1 has a higher rate of developing complications if treated with the wrong intervention. Strain 2 has a more expensive early intervention as well as a more costly treatment for flu complications, but patients with strain 2 has a lower rate of developing complications if treated with the wrong intervention. With no intervention, flu patients develop complications at the same rate regardless of the strain. \n",
    "\n",
    "**Your task:** build a model to predict if a given patient has the flu and identify the flu strain. The state government of MA will use your model to inform public health policies: we will vaccinate people you've identified as healthy and apply corresponding interventions to patients with different strains of the flu. We have provided you with a function to compute the total expected cost of this policy decision that takes into account the cost of the vaccine, the interventions and the cost of the treatments for flu complications resulting from misdiagnosing patients. Your goal is to make sure your model produces a public health policy with the lowest associated expected cost.\n",
    "\n",
    "**The deliverable:** a function called `flu_predict` which satisfies:\n",
    "\n",
    "- input: `x_test`, a set of medical predictors for a group of patients\n",
    "- output: `y_pred`, a set of labels, one for each patient; 1 for healthy, 2 for infected with strain 1, and 3 for infected with strain 2.\n",
    "\n",
    "The MA state government will use your model to diagnose sets of future patients (held by us). You can expect that there will be an increase in the number of flu patients in any groups of patients in the future.\n",
    "\n",
    "We provide you with some benchmarks for comparison.\n",
    "\n",
    "**Three Baseline Models:** \n",
    "- expected cost on observed data: \\$6,818,206.0, \\$7,035,735.0, \\$8,297,197.5\n",
    "- time to build: 1 min\n",
    "\n",
    "**Reasonable Model:** \n",
    "- expected cost on observed data: $6,300,000\n",
    "- time to build: 20 min\n",
    "\n",
    "**Grading:**\n",
    "Your grade will be based on:\n",
    "1. your model's ability to out-perform our benchmarks\n",
    "2. your ability to carefully and thoroughly follow the data science pipeline (see lecture slides for definition)\n",
    "3. the extend to which all choices are reasonable and defensible by methods you have learned in this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------  cost\n",
    "# A function that computes the expected cost of the public healthy policy based on the \n",
    "# classifications generated by your model\n",
    "# Input: \n",
    "#      y_true (true class labels: 0, 1, 2)\n",
    "#      y_pred (predicted class labels: 0, 1, 2)\n",
    "# Returns: \n",
    "#      total_cost (expected total cost)\n",
    "\n",
    "def cost(y_true, y_pred):\n",
    "    cost_of_treatment_1 = 29500\n",
    "    cost_of_treatment_2 = 45000\n",
    "    cost_of_intervention_1 = 4150\n",
    "    cost_of_intervention_2 = 4250\n",
    "    cost_of_vaccine = 15\n",
    "    \n",
    "    prob_complications_untreated = 0.65\n",
    "    prob_complications_1 = 0.30\n",
    "    prob_complications_2 = 0.15\n",
    "    \n",
    "    trials = 1000\n",
    "    \n",
    "    \n",
    "    intervention_cost = cost_of_intervention_1 * len(y_pred[y_pred==1]) + cost_of_intervention_2 * len(y_pred[y_pred==2])\n",
    "\n",
    "    vaccine_cost = cost_of_vaccine * len(y_pred[y_pred==0])\n",
    "    \n",
    "    false_neg_1 = ((y_true == 1) & (y_pred == 2)).sum()\n",
    "    false_neg_2 = ((y_true == 2) & (y_pred == 1)).sum()\n",
    "    \n",
    "    untreated_1 = ((y_true == 1) & (y_pred == 0)).sum()    \n",
    "    untreated_2 = ((y_true == 2) & (y_pred == 0)).sum()\n",
    "    \n",
    "    false_neg_1_cost = np.random.binomial(1, prob_complications_1, (false_neg_1, trials)) * cost_of_treatment_1\n",
    "    false_neg_2_cost = np.random.binomial(1, prob_complications_2, (false_neg_2, trials)) * cost_of_treatment_2\n",
    "    untreated_1_cost = np.random.binomial(1, prob_complications_untreated, (untreated_1, trials)) * cost_of_treatment_1\n",
    "    untreated_2_cost = np.random.binomial(1, prob_complications_untreated, (untreated_2, trials)) * cost_of_treatment_2\n",
    "    \n",
    "    false_neg_1_cost = false_neg_1_cost.sum(axis=0)\n",
    "    expected_false_neg_1_cost = false_neg_1_cost.mean()\n",
    "    \n",
    "    false_neg_2_cost = false_neg_2_cost.sum(axis=0)\n",
    "    expected_false_neg_2_cost = false_neg_2_cost.mean()\n",
    "    \n",
    "    untreated_1_cost = untreated_1_cost.sum(axis=0)\n",
    "    expected_untreated_1_cost = untreated_1_cost.mean()\n",
    "    \n",
    "    untreated_2_cost = untreated_2_cost.sum(axis=0)\n",
    "    expected_untreated_2_cost = untreated_2_cost.mean()\n",
    "    \n",
    "    total_cost = vaccine_cost + intervention_cost + expected_false_neg_1_cost + expected_false_neg_2_cost + expected_untreated_1_cost + expected_untreated_2_cost\n",
    "    \n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the dataset, there are 5246 entries, with 76 datapoints each.\n",
      "-------------------------\n",
      "There are 4936 people with no flu in the data set\n",
      "There are 227 people with no type 1 flu in the data set, with prevalence 0.043\n",
      "There are 83 people with no type 2 flu in the data set, with prevalence 0.016\n"
     ]
    }
   ],
   "source": [
    "flu_data = pd.read_csv('flu_train.csv', delimiter=',', header=0)\n",
    "flu_data2 = pd.read_csv('flu_test_no_y.csv', delimiter=',', header=0)\n",
    "\n",
    "x = flu_data.iloc[:, :-2]\n",
    "y = flu_data.iloc[:, -1]\n",
    "x2 = flu_data2.iloc[:, :-2]\n",
    "types = y.value_counts()\n",
    "\n",
    "print \"In the dataset, there are\", flu_data.shape[0], \"entries, with\", flu_data.shape[1], \"datapoints each.\"\n",
    "print \"-------------------------\"\n",
    "print \"There are\", types[1], \"people with no flu in the data set\"\n",
    "print \"There are\", types[2], \"people with no type 1 flu in the data set, with prevalence\", round(types[2]/float(len(flu_data)), 3)\n",
    "print \"There are\", types[3], \"people with no type 2 flu in the data set, with prevalence\", round(types[3]/float(len(flu_data)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = flu_data.iloc[:, :-2]\n",
    "\n",
    "#drop duplicative/unnecessary data\n",
    "cols = [2,3,9,11,16,17,20,21,25,26,27,28,29,36,37,42,43,48,49,57,59]\n",
    "x.drop(x.columns[cols],axis=1,inplace=True)\n",
    "\n",
    "#fill empty cells\n",
    "x.fillna(0, inplace=True)\n",
    "\n",
    "# Create a new data frame to store one-hot encoding of attributes\n",
    "flu_data_expanded = pd.DataFrame({}) \n",
    "\n",
    "# Iterate over all attributes\n",
    "for column in x.columns:\n",
    "    # Check if attribute is categorical: has less than 8 unique values,\n",
    "    # or is string values (column has type 'object')\n",
    "    if len(x[column].unique()) < 8 or x[column].dtype == np.dtype('object'):\n",
    "        # use one-hot encoding for this column\n",
    "        encoding = pd.get_dummies(x[column])\n",
    "        # append expanded attribute to data frame\n",
    "        flu_data_expanded = pd.concat([flu_data_expanded, encoding], axis=1)\n",
    "    else:\n",
    "        flu_data_expanded = pd.concat([flu_data_expanded, x[[column]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split data\n",
    "x_train = flu_data_expanded.iloc[:525, :]\n",
    "y_train = y.iloc[:525]\n",
    "x_val = flu_data_expanded.iloc[525:1050, :]\n",
    "y_val = y.iloc[525:1050]\n",
    "x_test = flu_data_expanded.iloc[1050:, :]\n",
    "y_test = y.iloc[1050:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the best we can possibly do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1368840.0"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ychange = y - 1\n",
    "cost(ychange, ychange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "So the best we can possibly do is to charge $1,368,840 with a perfect predictive model on the training set. Let's just fit a super-naive model and see how we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86412111.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "AdaBoost = AdaBoostClassifier()\n",
    "boost_fit = AdaBoost.fit(x_train, y_train)\n",
    "predictions = AdaBoost.predict(flu_data_expanded)\n",
    "predictions = predictions - 1\n",
    "print cost(y, predictions)\n",
    "cost_weighting.append(cost(y, predictions))\n",
    "ensemble['boost'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze and iterate\n",
    "So being out $86mil is not that good. Let's check out how our previous estimator does on this dataset when we combine binary estimators...\n",
    "\n",
    "One thing to justify - in the cases where we have ambiguous results (one 1, one 2 and one 3 vote), we'll assume that there is no flu since this is statistically the most likely scenario and our model does introduce some false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_fit(x, model):\n",
    "    cust_predict = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        exp = np.sum((x.iloc[i].values * model.coef_)) + model.intercept_\n",
    "        pred = 1 / (1 + math.exp(-exp))\n",
    "        if pred <= 0.025:\n",
    "            cust_predict.append(0)\n",
    "        else:\n",
    "            cust_predict.append(1)\n",
    "    \n",
    "    return cust_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    12  13  23  pred\n",
      "0    1   0   1     1\n",
      "1    1   0   1     1\n",
      "2    1   0   1     1\n",
      "3    1   0   1     1\n",
      "4    0   0   1     1\n",
      "5    0   1   1     3\n",
      "6    0   0   1     1\n",
      "7    0   0   1     1\n",
      "8    1   0   1     1\n",
      "9    0   0   1     1\n",
      "10   1   1   1     3\n",
      "11   1   0   1     1\n",
      "12   1   0   1     1\n",
      "13   1   0   1     1\n",
      "14   0   0   1     1\n",
      "15   1   0   1     1\n",
      "16   1   0   1     1\n",
      "17   0   0   1     1\n",
      "18   1   1   1     3\n",
      "19   1   0   1     1\n",
      "20   1   0   1     1\n",
      "21   1   0   1     1\n",
      "22   1   0   1     1\n",
      "23   0   0   1     1\n",
      "24   0   0   1     1\n"
     ]
    }
   ],
   "source": [
    "binary_pred = pd.DataFrame({}) \n",
    "\n",
    "#ignore 3's\n",
    "x12_binary = x_train[y_train != 3]\n",
    "y12_binary = y_train[y_train != 3]\n",
    "y12_binary = y12_binary-1\n",
    "\n",
    "#fit custom logistic regression without 3's\n",
    "logreg12 = LogisticRegression(C=(10**-3))\n",
    "logreg12.fit(x12_binary, y12_binary)\n",
    "predict12 = custom_fit(flu_data_expanded, logreg12)\n",
    "binary_pred['12'] = predict12\n",
    "\n",
    "#ignore 2's\n",
    "x13_binary = x_train[y_train != 2]\n",
    "y13_binary = y_train[y_train != 2]\n",
    "for each in range(len(y13_binary)):\n",
    "    if y13_binary.iloc[each] == 1:\n",
    "        y13_binary.iloc[each] = 0\n",
    "    if y13_binary.iloc[each] == 3:\n",
    "        y13_binary.iloc[each] = 1\n",
    "\n",
    "#fit custom logistic regression without 2's\n",
    "logreg13 = LogisticRegression(C=(10**-3))\n",
    "logreg13.fit(x13_binary, y13_binary)\n",
    "predict13 = custom_fit(flu_data_expanded, logreg13)\n",
    "binary_pred['13'] = predict13\n",
    "\n",
    "#ignore 1's\n",
    "x23_binary = x_train[y_train != 1]\n",
    "y23_binary = y_train[y_train != 1]\n",
    "for each in range(len(y23_binary)):\n",
    "    if y23_binary.iloc[each] == 2:\n",
    "        y23_binary.iloc[each] = 0\n",
    "    if y23_binary.iloc[each] == 3:\n",
    "        y23_binary.iloc[each] = 1\n",
    "\n",
    "#fit custom logistic regression without 1's\n",
    "logreg23 = LogisticRegression(C=(10**-3))\n",
    "logreg23.fit(x23_binary, y23_binary)\n",
    "predict23 = custom_fit(flu_data_expanded, logreg23)\n",
    "binary_pred['23'] = predict23\n",
    "\n",
    "predictions = []\n",
    "#Make our predictions\n",
    "for each in range(len(binary_pred)):\n",
    "    if binary_pred.iloc[each, 0] == 0 and binary_pred.iloc[each, 1] == 0 and binary_pred.iloc[each, 2] == 0:\n",
    "        predictions.append(1)\n",
    "    if binary_pred.iloc[each, 0] == 0 and binary_pred.iloc[each, 1] == 0 and binary_pred.iloc[each, 2] == 1:\n",
    "        predictions.append(1)\n",
    "    if binary_pred.iloc[each, 0] == 0 and binary_pred.iloc[each, 1] == 1 and binary_pred.iloc[each, 2] == 0:\n",
    "        predictions.append(1)\n",
    "    if binary_pred.iloc[each, 0] == 0 and binary_pred.iloc[each, 1] == 1 and binary_pred.iloc[each, 2] == 1:\n",
    "        predictions.append(3)\n",
    "    if binary_pred.iloc[each, 0] == 1 and binary_pred.iloc[each, 1] == 0 and binary_pred.iloc[each, 2] == 0:\n",
    "        predictions.append(2)\n",
    "    if binary_pred.iloc[each, 0] == 1 and binary_pred.iloc[each, 1] == 0 and binary_pred.iloc[each, 2] == 1:\n",
    "        predictions.append(1)\n",
    "    if binary_pred.iloc[each, 0] == 1 and binary_pred.iloc[each, 1] == 1 and binary_pred.iloc[each, 2] == 0:\n",
    "        predictions.append(2)\n",
    "    if binary_pred.iloc[each, 0] == 1 and binary_pred.iloc[each, 1] == 1 and binary_pred.iloc[each, 2] == 1:\n",
    "        predictions.append(3)\n",
    "\n",
    "preds = pd.Series(predictions)\n",
    "binary_pred['pred'] = preds\n",
    "print binary_pred.iloc[:25, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our predictions... how does our model do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97415902.5\n"
     ]
    }
   ],
   "source": [
    "ensemble = pd.DataFrame({}) \n",
    "cost_weighting = []\n",
    "preds_alter = preds - 1\n",
    "print cost(y, preds_alter)\n",
    "cost_weighting.append(cost(y, preds_alter))\n",
    "\n",
    "ensemble['logreg'] = preds_alter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze and iterate part 2\n",
    "Ouch... what we see here is that our model from the previous problem doesn't do a spectacular job. We'll keep it in the mix, for now because what we're going to do is fit a bunch of different models. If one of them works really well, we'll use that one but if we don't get a really good one, we can just use all of our different models as an \"ensemble\", take a majority vote, and hopefully perform much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92941533.5\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "costs = []\n",
    "\n",
    "for each in range(1, 20):\n",
    "    LDA = LinearDiscriminantAnalysis(n_components = each)\n",
    "    lda_fit = LDA.fit(x_train, y_train)\n",
    "    predictions = LDA.predict(flu_data_expanded)\n",
    "    predictions = predictions - 1\n",
    "    costs.append(cost(y, predictions))\n",
    "\n",
    "min_index = costs.index(min(costs))\n",
    "LDA = LinearDiscriminantAnalysis(n_components = min_index)\n",
    "lda_fit = LDA.fit(x_train, y_train)\n",
    "predictions = LDA.predict(flu_data_expanded)\n",
    "predictions = predictions - 1\n",
    "print cost(y, predictions)\n",
    "cost_weighting.append(cost(y, predictions))\n",
    "ensemble['lda'] = predictions\n",
    "print min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101396457.5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "costs = []\n",
    "\n",
    "for each in range(-5, 6):\n",
    "    reg = 10**each\n",
    "    QDA = QuadraticDiscriminantAnalysis(reg_param=reg)\n",
    "    qda_fit = QDA.fit(x_train, y_train)\n",
    "    predictions = QDA.predict(flu_data_expanded)\n",
    "    predictions = predictions - 1\n",
    "    costs.append(cost(y, predictions))\n",
    " \n",
    "min_index = costs.index(min(costs))\n",
    "QDA = QuadraticDiscriminantAnalysis(reg_param = (min_index-5))\n",
    "qda_fit = QDA.fit(x_train, y_train)\n",
    "predictions = QDA.predict(flu_data_expanded)\n",
    "predictions = predictions - 1\n",
    "print cost(y, predictions)\n",
    "cost_weighting.append(cost(y, predictions))\n",
    "ensemble['qda'] = predictions\n",
    "print min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernels = ['linear', 'rbf', 'sigmoid']\n",
    "K_costs = []\n",
    "C_costs = []\n",
    "\n",
    "for each in range(len(kernels)):\n",
    "    SVM = SVC(kernel = kernels[each])\n",
    "    svc_fit = SVM.fit(x_train, y_train)\n",
    "    predictions = SVM.predict(flu_data_expanded)\n",
    "    predictions = predictions - 1\n",
    "    K_costs.append(cost(y, predictions))\n",
    "\n",
    "min_kernel = K_costs.index(min(K_costs))\n",
    "for each in range(-5, 6):\n",
    "    C = 10**each\n",
    "    SVM = SVC(kernel = kernels[min_kernel], C=C)\n",
    "    svc_fit = SVM.fit(x_train, y_train)\n",
    "    predictions = SVM.predict(flu_data_expanded)\n",
    "    predictions = predictions - 1\n",
    "    C_costs.append(cost(y, predictions))\n",
    "    \n",
    "min_C = C_costs.index(min(C_costs))\n",
    "C = 10**(min_C-5)\n",
    "SVM = SVC(kernel = kernels[min_kernel], C=C)\n",
    "svc_fit = SVM.fit(x_train, y_train)\n",
    "predictions = SVM.predict(flu_data_expanded)\n",
    "predictions = predictions - 1   \n",
    "print cost(y, predictions)\n",
    "cost_weighting.append(cost(y, predictions))\n",
    "ensemble['svc'] = predictions\n",
    "print min_kernel, min_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56897745.5\n"
     ]
    }
   ],
   "source": [
    "D_costs = []\n",
    "F_costs = []\n",
    "\n",
    "\n",
    "for each in range(1, 50):\n",
    "    dt = DecisionTree(max_depth = each)\n",
    "    dt_fit = dt.fit(x_train, y_train)\n",
    "    predictions = dt.predict(flu_data_expanded)\n",
    "    predictions = predictions - 1\n",
    "    D_costs.append(cost(y, predictions))\n",
    "\n",
    "min_depth = D_costs.index(min(D_costs))\n",
    "for each in range(1, 20):\n",
    "    dt = DecisionTree(max_depth = min_depth, max_features = each)\n",
    "    dt_fit = dt.fit(x_train, y_train)\n",
    "    predictions = dt.predict(flu_data_expanded)\n",
    "    predictions = predictions - 1\n",
    "    F_costs.append(cost(y, predictions))\n",
    "    \n",
    "min_feat = F_costs.index(min(F_costs))\n",
    "dt = DecisionTree(max_depth = min_depth, max_features = min_feat)\n",
    "dt_fit = dt.fit(x_train, y_train)\n",
    "predictions = dt.predict(flu_data_expanded)\n",
    "predictions = predictions - 1   \n",
    "print cost(y, predictions)\n",
    "cost_weighting.append(cost(y, predictions))\n",
    "ensemble['dt'] = predictions\n",
    "print min_depth, min_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97131041.0\n"
     ]
    }
   ],
   "source": [
    "costs = []\n",
    "\n",
    "for each in range(2, 25):\n",
    "    rf = RandomForest(n_estimators = each)\n",
    "    rf_fit = rf.fit(x_train, y_train)\n",
    "    predictions = rf.predict(flu_data_expanded)\n",
    "    predictions = predictions - 1\n",
    "    costs.append(cost(y, predictions))\n",
    "\n",
    "min_index = costs.index(min(costs))\n",
    "rf = RandomForest(n_estimators = min_index)\n",
    "rf_fit = rf.fit(x_train, y_train)\n",
    "predictions = rf.predict(flu_data_expanded)\n",
    "predictions = predictions - 1\n",
    "print cost(y, predictions)\n",
    "cost_weighting.append(cost(y, predictions))\n",
    "ensemble['rf'] = predictions\n",
    "print min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86355607.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "AdaBoost = AdaBoostClassifier()\n",
    "boost_fit = AdaBoost.fit(x_train, y_train)\n",
    "predictions = AdaBoost.predict(flu_data_expanded)\n",
    "predictions = predictions - 1\n",
    "print cost(y, predictions)\n",
    "cost_weighting.append(cost(y, predictions))\n",
    "ensemble['boost'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    logreg  lda  qda  svc  majvote  dt  rf  boost\n",
      "0        0    0    0    0        0   0   0      1\n",
      "1        0    0    0    0        0   0   1      1\n",
      "2        0    0    0    0        0   0   0      1\n",
      "3        0    0    0    0        0   0   0      0\n",
      "4        0    0    0    0        0   0   0      0\n",
      "5        0    0    0    0        0   0   0      0\n",
      "6        0    0    0    0        0   0   0      0\n",
      "7        0    0    0    0        0   0   0      0\n",
      "8        0    1    0    0        0   0   0      0\n",
      "9        0    0    0    0        0   0   0      0\n",
      "10       2    0    0    0        0   0   0      0\n",
      "11       0    0    0    0        0   0   0      1\n",
      "12       0    0    0    0        0   0   0      0\n",
      "13       0    0    0    0        0   0   0      0\n",
      "14       0    0    0    0        0   0   0      0\n",
      "15       0    0    0    0        0   0   0      0\n",
      "16       0    0    0    0        0   0   0      0\n",
      "17       0    0    0    0        0   0   0      0\n",
      "18       2    0    0    0        0   0   0      1\n",
      "19       2    0    0    0        0   0   0      0\n",
      "70255710.5\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "for i in range(len(ensemble)):\n",
    "    counts = np.bincount(ensemble.iloc[i, :])\n",
    "    prediction.append(np.argmax(counts))\n",
    "ensemble['majvote'] = prediction\n",
    "print ensemble[:20]\n",
    "\n",
    "print cost(y_test, ensemble.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flu_predict2(x_test):\n",
    "    #drop duplicative/unnecessary columns\n",
    "    cols = [2,3,9,11,16,17,20,21,25,26,27,28,29,36,37,42,43,48,49,57,59]\n",
    "    x_test.drop(x_test.columns[cols],axis=1,inplace=True)\n",
    "\n",
    "    #fill blank entries\n",
    "    x_test.fillna(0, inplace=True)\n",
    "\n",
    "    # Create a new data frame to store one-hot encoding of attributes\n",
    "    flu_data_expanded = pd.DataFrame({}) \n",
    "\n",
    "    # Iterate over all attributes\n",
    "    for column in x_test.columns:\n",
    "        # Check if attribute is categorical: has less than 8 unique values,\n",
    "        # or is string values (column has type 'object')\n",
    "        if len(x_test[column].unique()) < 8 or x_test[column].dtype == np.dtype('object'):\n",
    "            # use one-hot encoding for this column\n",
    "            encoding = pd.get_dummies(x_test[column])\n",
    "            # append expanded attribute to data frame\n",
    "            flu_data_expanded = pd.concat([flu_data_expanded, encoding], axis=1)\n",
    "        else:\n",
    "            flu_data_expanded = pd.concat([flu_data_expanded, x_test[[column]]], axis=1)\n",
    "            \n",
    "    #Fit Logistic Regression\n",
    "    ensemble = pd.DataFrame({})\n",
    "    costs = []\n",
    "    \n",
    "    LogReg = LogisticRegression()\n",
    "    LR_fit = LogReg.fit(x_train, y_train)\n",
    "    predictions = LogReg.predict(flu_data_expanded)\n",
    "    predictions = predictions - 1\n",
    "    ensemble['logreg'] = predictions\n",
    "    \n",
    "    #Fit LDA\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "    LDA = LinearDiscriminantAnalysis(n_components = 13)\n",
    "    lda_fit = LDA.fit(x_train, y_train)\n",
    "    predictions = LDA.predict(flu_data_expanded)\n",
    "    predictions = predictions - 1\n",
    "    cost_weighting.append(cost(y, predictions))\n",
    "    ensemble['lda'] = predictions\n",
    "    \n",
    "    #fit QDA\n",
    "    from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "    min_index = costs.index(min(costs))\n",
    "    QDA = QuadraticDiscriminantAnalysis(reg_param = (10**-5))\n",
    "    qda_fit = QDA.fit(x_train, y_train)\n",
    "    predictions = QDA.predict(flu_data_expanded)\n",
    "    predictions = predictions - 1\n",
    "    cost_weighting.append(cost(y, predictions))\n",
    "    ensemble['qda'] = predictions\n",
    "    \n",
    "    #fit SVC\n",
    "    SVM = SVC(kernel = kernels[min_kernel], C=C)\n",
    "    svc_fit = SVM.fit(x_train, y_train)\n",
    "    predictions = SVM.predict(flu_data_expanded)\n",
    "    predictions = predictions - 1   \n",
    "    cost_weighting.append(cost(y, predictions))\n",
    "    ensemble['svc'] = predictions\n",
    "    \n",
    "    #fit Decision Tree\n",
    "    D_costs = []\n",
    "    F_costs = []\n",
    "\n",
    "\n",
    "    for each in range(1, 50):\n",
    "        dt = DecisionTree(max_depth = each)\n",
    "        dt_fit = dt.fit(x_train, y_train)\n",
    "        predictions = dt.predict(flu_data_expanded)\n",
    "        predictions = predictions - 1\n",
    "        D_costs.append(cost(y, predictions))\n",
    "\n",
    "    min_depth = D_costs.index(min(D_costs))\n",
    "    for each in range(1, 20):\n",
    "        dt = DecisionTree(max_depth = min_depth, max_features = each)\n",
    "        dt_fit = dt.fit(x_train, y_train)\n",
    "        predictions = dt.predict(flu_data_expanded)\n",
    "        predictions = predictions - 1\n",
    "        F_costs.append(cost(y, predictions))\n",
    "\n",
    "    min_feat = F_costs.index(min(F_costs))\n",
    "    dt = DecisionTree(max_depth = min_depth, max_features = min_feat)\n",
    "    dt_fit = dt.fit(x_train, y_train)\n",
    "    predictions = dt.predict(flu_data_expanded)\n",
    "    predictions = predictions - 1   \n",
    "    cost_weighting.append(cost(y, predictions))\n",
    "    ensemble['dt'] = predictions\n",
    "    \n",
    "    #fit Random Forest\n",
    "    costs = []\n",
    "    for each in range(2, 25):\n",
    "        rf = RandomForest(n_estimators = each)\n",
    "        rf_fit = rf.fit(x_train, y_train)\n",
    "        predictions = rf.predict(flu_data_expanded)\n",
    "        predictions = predictions - 1\n",
    "        costs.append(cost(y, predictions))\n",
    "\n",
    "    min_index = costs.index(min(costs))\n",
    "    rf = RandomForest(n_estimators = min_index)\n",
    "    rf_fit = rf.fit(x_train, y_train)\n",
    "    predictions = rf.predict(flu_data_expanded)\n",
    "    predictions = predictions - 1\n",
    "    cost_weighting.append(cost(y, predictions))\n",
    "    ensemble['rf'] = predictions\n",
    "    \n",
    "    #fit AdaBoost\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    AdaBoost = AdaBoostClassifier()\n",
    "    boost_fit = AdaBoost.fit(x_train, y_train)\n",
    "    predictions = AdaBoost.predict(flu_data_expanded)\n",
    "    predictions = predictions - 1\n",
    "    cost_weighting.append(cost(y, predictions))\n",
    "    ensemble['boost'] = predictions\n",
    "    \n",
    "    #make a prediction\n",
    "    prediction = []\n",
    "    for i in range(len(ensemble)):\n",
    "        counts = np.bincount(ensemble.iloc[i, :])\n",
    "        prediction.append(np.argmax(counts))\n",
    "    ensemble['majvote'] = prediction\n",
    "\n",
    "    return ensemble['majvote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5246,) (1533,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-854-199db4b78426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mflu_data2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'flu_test_no_y.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflu_predict2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflu_data2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflu_data2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-853-a1b2d72460b0>\u001b[0m in \u001b[0;36mflu_predict2\u001b[0;34m(x_test)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflu_data_expanded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mcosts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mmin_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-560-6d4e07d76e18>\u001b[0m in \u001b[0;36mcost\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mvaccine_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_of_vaccine\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mfalse_neg_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mfalse_neg_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    834\u001b[0m                       is_integer_dtype(np.asarray(other)) else fill_bool)\n\u001b[1;32m    835\u001b[0m             return filler(self._constructor(\n\u001b[0;32m--> 836\u001b[0;31m                 \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m                 index=self.index)).__finalize__(self)\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5246,) (1533,) "
     ]
    }
   ],
   "source": [
    "flu_data2 = pd.read_csv('flu_test_no_y.csv', delimiter=',', header=0)\n",
    "\n",
    "predictions = flu_predict2(flu_data2)\n",
    "ids = []\n",
    "for each in range(len(flu_data2)):\n",
    "    ids.append(flu_data2.iloc[each, 0])\n",
    "    \n",
    "#export a file\n",
    "with io.FileIO(\"preds.txt\", \"w\") as file:\n",
    "    file.write(\"index,label\\n\")\n",
    "    for each in range(1, (len(predictions)+1)):\n",
    "            file.write(str(ids[(each-1)]) + \",\" + str(predictions[(each-1)]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendices\n",
    "\n",
    "## Appendix A - Dropped Columns\n",
    "- Age\n",
    "- AgeDecade\n",
    "- HHIncome\n",
    "- Poverty\n",
    "- Length\n",
    "- HeadCircumference\n",
    "- BMI Category\n",
    "- BMI WHO\n",
    "- Urine Volume 2\n",
    "- Urine Flow 2\n",
    "- Little Interest\n",
    "- Depressed\n",
    "- Physically Active\n",
    "- Alcohol year\n",
    "\n",
    "## Appendix B - Testing the Get_Stats function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.667, 0.5, 0.5, 0.333)\n"
     ]
    }
   ],
   "source": [
    "#test get_stats\n",
    "test = [1, 1, 0, 0, 1]\n",
    "actual = pd.DataFrame([0, 1, 0, 1, 1])\n",
    "\n",
    "print get_stats(test, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix C - Get Bad Data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_bad_data(x):\n",
    "    nan_indices = []\n",
    "    inf_indices = []\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            if np.isnan(x.iloc[i,j]):\n",
    "                nan_indices.append('['+`i`+','+`j`+']')\n",
    "            if np.isinf(x.iloc[i,j]):\n",
    "                inf_indices.append('['+`i`+','+`j`+']')\n",
    "    print nan_indices\n",
    "    print \"-------------------------\"\n",
    "    print inf_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix D - Part 1 Analysis and Iteration #2\n",
    "So, we're doing okay with this new model. Around 0.025 probability we can get both 50% true positive and 50% true negative, and tweak things up or down from there. But I'd like to see what would happen if we sub-sample our data... let's see if we can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subtrain1 = flu_data_expanded[y == 1]\n",
    "subtrain2 = flu_data_expanded[y != 1]\n",
    "\n",
    "n = len(subtrain1)\n",
    "subtrain3 = subtrain2[:n]\n",
    "\n",
    "lists = [subtrain1, subtrain3]\n",
    "x_concat = pd.concat(lists, axis = 0)\n",
    "\n",
    "y_subtrain = y[y == 1]\n",
    "y_subtrain2 = y[y != 1]\n",
    "y_subtrain2 = y_subtrain2[:n]\n",
    "\n",
    "lists = [y_subtrain, y_subtrain2]\n",
    "y_concat = pd.concat(lists, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- True Negative : True Positive---\n",
      "--------------------------------------------------------\n",
      "At probability 0.01 -         0.068 : 0.794\n",
      "At probability 0.02 -         0.245 : 0.613\n",
      "At probability 0.03 -         0.435 : 0.458\n",
      "At probability 0.04 -         0.571 : 0.358\n",
      "At probability 0.05 -         0.677 : 0.319\n",
      "At probability 0.06 -         0.771 : 0.274\n",
      "At probability 0.07 -         0.826 : 0.242\n",
      "At probability 0.08 -         0.861 : 0.219\n",
      "At probability 0.09 -         0.874 : 0.194\n",
      "At probability 0.1 -         0.919 : 0.187\n"
     ]
    }
   ],
   "source": [
    "sens = []\n",
    "spec = []\n",
    "fps = []\n",
    "fns = []\n",
    "increments = []\n",
    "for each in range(1, 11):\n",
    "    log_prob = 0.01*each\n",
    "    sensitivity, specificity, fp, fn, predictions = tune_specificity(x_concat, y_concat, log_prob)\n",
    "    sens.append(sensitivity)\n",
    "    spec.append(specificity)\n",
    "    fps.append(fp)\n",
    "    fns.append(fn)\n",
    "    increments.append(log_prob)\n",
    "    \n",
    "print \"--------------------- True Negative : True Positive---\"\n",
    "print \"--------------------------------------------------------\"\n",
    "\n",
    "for each in range(len(increments)):\n",
    "    print \"At probability\", increments[each], \"-        \", spec[each],\":\",sens[each]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix E - What we tried in part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sensitivity (True Positive) rate of the model is: 0.0\n",
      "The specificity (True Negative) rate of the model is: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "KNN = KNN(n_neighbors = 5)\n",
    "KNN_fit = KNN.fit(x_train, y_train)\n",
    "predictions = KNN.predict(x_test)\n",
    "sensitivity, specificity, fp, fn = get_stats(predictions, y_test)\n",
    "print \"The sensitivity (True Positive) rate of the model is:\", sensitivity\n",
    "print \"The specificity (True Negative) rate of the model is:\", specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sensitivity (True Positive) rate of the model is: 0.074\n",
      "The specificity (True Negative) rate of the model is: 0.962\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForest(n_estimators = 1, max_depth = 10)\n",
    "rf_fit = rf.fit(x_train, y_train)\n",
    "predictions = rf.predict(x_test)\n",
    "sensitivity, specificity, fp, fn = get_stats(predictions, y_test)\n",
    "print \"The sensitivity (True Positive) rate of the model is:\", sensitivity\n",
    "print \"The specificity (True Negative) rate of the model is:\", specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sensitivity (True Positive) rate of the model is: 0.025\n",
      "The specificity (True Negative) rate of the model is: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "AdaBoost = AdaBoostClassifier()\n",
    "boost_fit = AdaBoost.fit(x_train, y_train)\n",
    "predictions = AdaBoost.predict(x_test)\n",
    "sensitivity, specificity, fp, fn = get_stats(predictions, y_test)\n",
    "print \"The sensitivity (True Positive) rate of the model is:\", sensitivity\n",
    "print \"The specificity (True Negative) rate of the model is:\", specificity"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
